{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0eae7ba",
   "metadata": {},
   "source": [
    "# LLM Groq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e57b56",
   "metadata": {},
   "source": [
    "This notebook uses the Groq API to generate different LLMs' (Llama, Qwen, GPT) predictions on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d0fe43",
   "metadata": {},
   "source": [
    "## 0. Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b37c2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4==4.13.5 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (4.13.5)\n",
      "Requirement already satisfied: datasets==3.6.0 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (3.6.0)\n",
      "Requirement already satisfied: dotenv==0.9.9 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (0.9.9)\n",
      "Requirement already satisfied: google-genai>=1.51.0 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (1.51.0)\n",
      "Requirement already satisfied: groq==0.36.0 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (0.36.0)\n",
      "Requirement already satisfied: imbalanced-learn==0.14.0 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (0.14.0)\n",
      "Requirement already satisfied: imblearn==0.0 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from -r requirements.txt (line 7)) (0.0)\n",
      "Requirement already satisfied: ipykernel==6.17.1 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from -r requirements.txt (line 8)) (6.17.1)\n",
      "Requirement already satisfied: ipywidgets>=7.7.1 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from -r requirements.txt (line 9)) (8.1.8)\n",
      "Requirement already satisfied: joblib==1.5.2 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from -r requirements.txt (line 10)) (1.5.2)\n",
      "Requirement already satisfied: matplotlib==3.10.0 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from -r requirements.txt (line 11)) (3.10.0)\n",
      "Requirement already satisfied: nltk==3.9.1 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from -r requirements.txt (line 12)) (3.9.1)\n",
      "Requirement already satisfied: numpy==2.0.2 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from -r requirements.txt (line 13)) (2.0.2)\n",
      "Requirement already satisfied: pandas==2.2.2 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from -r requirements.txt (line 14)) (2.2.2)\n",
      "Requirement already satisfied: polars==1.31.0 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from -r requirements.txt (line 15)) (1.31.0)\n",
      "Requirement already satisfied: requests==2.32.4 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from -r requirements.txt (line 16)) (2.32.4)\n",
      "Requirement already satisfied: scikit-learn==1.6.1 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from -r requirements.txt (line 17)) (1.6.1)\n",
      "Requirement already satisfied: scipy==1.16.3 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from -r requirements.txt (line 18)) (1.16.3)\n",
      "Requirement already satisfied: seaborn==0.13.2 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from -r requirements.txt (line 19)) (0.13.2)\n",
      "Requirement already satisfied: statsmodels==0.14.5 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from -r requirements.txt (line 20)) (0.14.5)\n",
      "Requirement already satisfied: tokenizers==0.22.1 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from -r requirements.txt (line 21)) (0.22.1)\n",
      "Requirement already satisfied: torch>=2.8.0 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from -r requirements.txt (line 22)) (2.8.0)\n",
      "Requirement already satisfied: torchaudio>=2.8.0 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from -r requirements.txt (line 23)) (2.8.0)\n",
      "Requirement already satisfied: torchvision>=0.23.0 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from -r requirements.txt (line 24)) (0.23.0)\n",
      "Requirement already satisfied: torchmetrics>=1.8.2 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from -r requirements.txt (line 25)) (1.8.2)\n",
      "Requirement already satisfied: tqdm==4.67.1 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from -r requirements.txt (line 26)) (4.67.1)\n",
      "Requirement already satisfied: transformers>=4.57.1 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from -r requirements.txt (line 27)) (4.57.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from beautifulsoup4==4.13.5->-r requirements.txt (line 1)) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from beautifulsoup4==4.13.5->-r requirements.txt (line 1)) (4.15.0)\n",
      "Requirement already satisfied: filelock in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from datasets==3.6.0->-r requirements.txt (line 2)) (3.20.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from datasets==3.6.0->-r requirements.txt (line 2)) (22.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from datasets==3.6.0->-r requirements.txt (line 2)) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from datasets==3.6.0->-r requirements.txt (line 2)) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from datasets==3.6.0->-r requirements.txt (line 2)) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 2)) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from datasets==3.6.0->-r requirements.txt (line 2)) (0.36.0)\n",
      "Requirement already satisfied: packaging in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from datasets==3.6.0->-r requirements.txt (line 2)) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from datasets==3.6.0->-r requirements.txt (line 2)) (6.0.3)\n",
      "Requirement already satisfied: python-dotenv in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from dotenv==0.9.9->-r requirements.txt (line 3)) (1.2.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from groq==0.36.0->-r requirements.txt (line 5)) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from groq==0.36.0->-r requirements.txt (line 5)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from groq==0.36.0->-r requirements.txt (line 5)) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from groq==0.36.0->-r requirements.txt (line 5)) (2.12.4)\n",
      "Requirement already satisfied: sniffio in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from groq==0.36.0->-r requirements.txt (line 5)) (1.3.1)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from imbalanced-learn==0.14.0->-r requirements.txt (line 6)) (3.6.0)\n",
      "Requirement already satisfied: appnope in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from ipykernel==6.17.1->-r requirements.txt (line 8)) (0.1.4)\n",
      "Requirement already satisfied: debugpy>=1.0 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from ipykernel==6.17.1->-r requirements.txt (line 8)) (1.8.17)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from ipykernel==6.17.1->-r requirements.txt (line 8)) (9.7.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from ipykernel==6.17.1->-r requirements.txt (line 8)) (8.6.3)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from ipykernel==6.17.1->-r requirements.txt (line 8)) (0.2.1)\n",
      "Requirement already satisfied: nest-asyncio in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from ipykernel==6.17.1->-r requirements.txt (line 8)) (1.6.0)\n",
      "Requirement already satisfied: psutil in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from ipykernel==6.17.1->-r requirements.txt (line 8)) (7.1.3)\n",
      "Requirement already satisfied: pyzmq>=17 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from ipykernel==6.17.1->-r requirements.txt (line 8)) (27.1.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from ipykernel==6.17.1->-r requirements.txt (line 8)) (6.5.2)\n",
      "Requirement already satisfied: traitlets>=5.1.0 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from ipykernel==6.17.1->-r requirements.txt (line 8)) (5.14.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from matplotlib==3.10.0->-r requirements.txt (line 11)) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from matplotlib==3.10.0->-r requirements.txt (line 11)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from matplotlib==3.10.0->-r requirements.txt (line 11)) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from matplotlib==3.10.0->-r requirements.txt (line 11)) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from matplotlib==3.10.0->-r requirements.txt (line 11)) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from matplotlib==3.10.0->-r requirements.txt (line 11)) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from matplotlib==3.10.0->-r requirements.txt (line 11)) (2.9.0.post0)\n",
      "Requirement already satisfied: click in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from nltk==3.9.1->-r requirements.txt (line 12)) (8.3.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from nltk==3.9.1->-r requirements.txt (line 12)) (2025.11.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from pandas==2.2.2->-r requirements.txt (line 14)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from pandas==2.2.2->-r requirements.txt (line 14)) (2025.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from requests==2.32.4->-r requirements.txt (line 16)) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from requests==2.32.4->-r requirements.txt (line 16)) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from requests==2.32.4->-r requirements.txt (line 16)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from requests==2.32.4->-r requirements.txt (line 16)) (2025.11.12)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from statsmodels==0.14.5->-r requirements.txt (line 20)) (1.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 2)) (3.13.2)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from httpx<1,>=0.23.0->groq==0.36.0->-r requirements.txt (line 5)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq==0.36.0->-r requirements.txt (line 5)) (0.16.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets==3.6.0->-r requirements.txt (line 2)) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->groq==0.36.0->-r requirements.txt (line 5)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->groq==0.36.0->-r requirements.txt (line 5)) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->groq==0.36.0->-r requirements.txt (line 5)) (0.4.2)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from google-genai>=1.51.0->-r requirements.txt (line 4)) (2.43.0)\n",
      "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from google-genai>=1.51.0->-r requirements.txt (line 4)) (9.1.2)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from google-genai>=1.51.0->-r requirements.txt (line 4)) (15.0.1)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from google-auth<3.0.0,>=2.14.1->google-genai>=1.51.0->-r requirements.txt (line 4)) (6.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from google-auth<3.0.0,>=2.14.1->google-genai>=1.51.0->-r requirements.txt (line 4)) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from google-auth<3.0.0,>=2.14.1->google-genai>=1.51.0->-r requirements.txt (line 4)) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.14.1->google-genai>=1.51.0->-r requirements.txt (line 4)) (0.6.1)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from ipywidgets>=7.7.1->-r requirements.txt (line 9)) (0.2.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from ipywidgets>=7.7.1->-r requirements.txt (line 9)) (4.0.15)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from ipywidgets>=7.7.1->-r requirements.txt (line 9)) (3.0.16)\n",
      "Requirement already satisfied: setuptools in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from torch>=2.8.0->-r requirements.txt (line 22)) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from torch>=2.8.0->-r requirements.txt (line 22)) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from torch>=2.8.0->-r requirements.txt (line 22)) (3.5)\n",
      "Requirement already satisfied: jinja2 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from torch>=2.8.0->-r requirements.txt (line 22)) (3.1.6)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from torchmetrics>=1.8.2->-r requirements.txt (line 25)) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from transformers>=4.57.1->-r requirements.txt (line 27)) (0.7.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 2)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 2)) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 2)) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 2)) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 2)) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 2)) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 2)) (1.22.0)\n",
      "Requirement already satisfied: decorator>=4.3.2 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel==6.17.1->-r requirements.txt (line 8)) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel==6.17.1->-r requirements.txt (line 8)) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.18.1 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel==6.17.1->-r requirements.txt (line 8)) (0.19.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel==6.17.1->-r requirements.txt (line 8)) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel==6.17.1->-r requirements.txt (line 8)) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.11.0 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel==6.17.1->-r requirements.txt (line 8)) (2.19.2)\n",
      "Requirement already satisfied: stack_data>=0.6.0 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel==6.17.1->-r requirements.txt (line 8)) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel==6.17.1->-r requirements.txt (line 8)) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from jedi>=0.18.1->ipython>=7.23.1->ipykernel==6.17.1->-r requirements.txt (line 8)) (0.8.5)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from jupyter-client>=6.1.12->ipykernel==6.17.1->-r requirements.txt (line 8)) (5.9.1)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-client>=6.1.12->ipykernel==6.17.1->-r requirements.txt (line 8)) (4.5.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel==6.17.1->-r requirements.txt (line 8)) (0.7.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib==3.10.0->-r requirements.txt (line 11)) (1.17.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel==6.17.1->-r requirements.txt (line 8)) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel==6.17.1->-r requirements.txt (line 8)) (3.0.1)\n",
      "Requirement already satisfied: pure-eval in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel==6.17.1->-r requirements.txt (line 8)) (0.2.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.8.0->-r requirements.txt (line 22)) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/envs/data512_project/lib/python3.12/site-packages (from jinja2->torch>=2.8.0->-r requirements.txt (line 22)) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9eee9e6",
   "metadata": {},
   "source": [
    "Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a991394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "from groq import Groq\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e60255",
   "metadata": {},
   "source": [
    "To use the LLM model provided by Groq, **you must obtain a Google API key from [here](https://aistudio.google.com/api-keys)￼ and place it in the `/.env` file as GEMINI_API_KEY=XXXXX. Without a valid API key**, the Gemini model cannot be called successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbf7545",
   "metadata": {},
   "source": [
    "## 1. Define Prompting Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf81c92",
   "metadata": {},
   "source": [
    "To make the notebook cleaner and improve how prompts and outputs are formatted, it’s better to define a prompt generator.\n",
    "Therefore, I created a prompt generator that produces prompts based on the provided arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8594061d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptGenerator:\n",
    "    def __init__(self, few_shot:bool, cot:bool, binary:bool =False) -> None: \n",
    "        self.few_shot = few_shot\n",
    "        self.cot = cot\n",
    "        self.binary = binary\n",
    "\n",
    "    def generate_general_instruction(self, batch_size:int) -> str:\n",
    "        '''\n",
    "            Create general instruction for sentiment analysis task\n",
    "        '''\n",
    "        if self.binary:\n",
    "            sentiment_scale = \"\"\"3.  **Sentiment Scale:** 0 = Negative and 1 =  Positive.\"\"\"\n",
    "        else:\n",
    "            sentiment_scale = \"\"\"3.  **Sentiment Scale:** Use a 5-point star rating (0 = Very Negative, 4 = Very Positive).\"\"\"\n",
    "        \n",
    "        general_instruction = f\"\"\"\n",
    "            Analyze the sentiment for the {batch_size} Amazon product reviews provided below.\n",
    "            The unique index for each review is provided in the '<review id=\"...\">' tag.\n",
    "\n",
    "            # --- INSTRUCTIONS & CONSTRAINTS ---\n",
    "            1.  **Strict Output:** Your final output MUST be a single, valid JSON object containing a 'reviews' array.\n",
    "            2.  **Indexing:** The 'index' field in your JSON output MUST correspond exactly to the 'id' extracted from the <review id=\"...\"> tag.\n",
    "            {sentiment_scale}\n",
    "            4.  **No Explanation:** Do NOT include any introductory text, explanation, your thought process, or any Markdown fences (like ```json or ```) outside of the required JSON object.\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        return general_instruction\n",
    "    \n",
    "    def generate_cot_instruction(self) -> str:\n",
    "        '''\n",
    "            Create Chain-of-Thought instruction for sentiment analysis task\n",
    "        '''\n",
    "        if self.binary:\n",
    "            scale = \"\"\"4. Assign the final sentiment rating (0 or 1).\"\"\"\n",
    "        else:\n",
    "            scale = \"\"\"4. Assign the final sentiment rating (0, 1, 2, 3, or 4).\"\"\"\n",
    "            \n",
    "        cot_instruction = f\"\"\"\n",
    "            # --- CHAIN OF THOUGHT (CoT) PROCESS ---\n",
    "            For each review, you MUST perform a Chain-of-Thought process and enclose it in a <CoT> XML tag. This process helps ensure accuracy. Your reasoning must follow these steps:\n",
    "            <CoT>\n",
    "            1. Identify the main sentiment/emotion (e.g., happiness, frustration, disappointment).\n",
    "            2. List specific positive aspects (+ve) and negative aspects (-ve) mentioned in the review.\n",
    "            3. Evaluate the overall net sentiment, giving appropriate weight to pros and cons.\n",
    "            {scale}\n",
    "            </CoT>\n",
    "            \n",
    "            You MUST include this <CoT> reasoning for each review in your response.\n",
    "            \"\"\"\n",
    "        \n",
    "        return cot_instruction\n",
    "\n",
    "    def generate_few_shot_examples(self) -> list:\n",
    "        '''\n",
    "            Create few-shot examples for sentiment analysis task.\n",
    "            I randomly selected some examples from the training set to illustrate both binary and multi-class sentiment analysis.\n",
    "        '''\n",
    "        if self.binary:\n",
    "            few_shot_examples = [\n",
    "                # --- Example 1 ---\n",
    "                {\n",
    "                    \"role\":\"user\",\n",
    "                    \"content\":\"\"\"<review id=\\\\'1\\\\'>So glad I could get my deodorant online at Amazon. This has a great scent too.</review>\"\"\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\":\"assistant\",\n",
    "                    \"content\":\"\"\"{{\"index\": '1', \"sentiment_rating\": \"1\"}}\"\"\",\n",
    "                },\n",
    "                # --- Example 2 ---\n",
    "                {\n",
    "                    \"role\":\"user\",\n",
    "                    \"content\":\"\"\"<review id=\\\\'5\\\\'>It is not organic , it's made in china, left my hair dry ... returning .</review>\"\"\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\":\"assistant\",\n",
    "                    \"content\":\"\"\"{{\"index\": '5', \"sentiment_rating\": \"0\"}}\"\"\",\n",
    "                },\n",
    "                # --- End of Few-Shot Examples ---\n",
    "            ]\n",
    "        else:\n",
    "            few_shot_examples = [\n",
    "                # --- Example 1 ---\n",
    "                {\n",
    "                    \"role\":\"user\",\n",
    "                    \"content\":\"\"\"<review id=\\\\'1\\\\'>So glad I could get my deodorant online at Amazon. This has a great scent too.</review>\"\"\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\":\"assistant\",\n",
    "                    \"content\":\"\"\"{{\"index\": '1', \"sentiment_rating\": \"4\"}}\"\"\",\n",
    "                },\n",
    "                # --- Example 2 ---\n",
    "                {\n",
    "                    \"role\":\"user\",\n",
    "                    \"content\":\"\"\"<review id=\\\\'2\\\\'>extremely metallic, two coats does the trick. however, the chemical smell is EXTREMELY strong. you need to open a window and run a fan while applying.</review>\"\"\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\":\"assistant\",\n",
    "                    \"content\":\"\"\"{{\"index\": '2', \"sentiment_rating\": \"3\"}}\"\"\",\n",
    "                },\n",
    "                # --- Example 3 ---\n",
    "                {\n",
    "                    \"role\":\"user\",\n",
    "                    \"content\":\"\"\"<review id=\\\\'3\\\\'>Very, very thin,, not to absorbent</review>\"\"\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\":\"assistant\",\n",
    "                    \"content\":\"\"\"{{\"index\": '3', \"sentiment_rating\": \"2\"}}\"\"\",\n",
    "                },\n",
    "                # --- Example 4 ---\n",
    "                {\n",
    "                    \"role\":\"user\",\n",
    "                    \"content\":\"\"\"<review id=\\\\'4\\\\'>Relatively short and not good for kinky hair.</review>\"\"\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\":\"assistant\",\n",
    "                    \"content\":\"\"\"{{\"index\": '4', \"sentiment_rating\": \"1\"}}\"\"\",\n",
    "                },\n",
    "                # --- Example 5 ---\n",
    "                {\n",
    "                    \"role\":\"user\",\n",
    "                    \"content\":\"\"\"<review id=\\\\'5\\\\'>It is not organic , it's made in china, left my hair dry ... returning .</review>\"\"\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\":\"assistant\",\n",
    "                    \"content\":\"\"\"{{\"index\": '5', \"sentiment_rating\": \"0\"}}\"\"\",\n",
    "                },\n",
    "                # --- End of Few-Shot Examples ---\n",
    "            ]\n",
    "        return few_shot_examples\n",
    "\n",
    "\n",
    "    def generate_final_instruction(self, text_batch: str) -> str:\n",
    "        '''\n",
    "            Create review test sets as final instruction for sentiment analysis task\n",
    "        '''\n",
    "        final_instruction = f\"\"\"\n",
    "                --- REVIEWS START ---\n",
    "                {text_batch}\n",
    "                --- REVIEWS END ---\n",
    "            \"\"\"\n",
    "        return final_instruction\n",
    "\n",
    "    def gen_query(self, batch_size: int, text_batch: str) -> list:\n",
    "        '''\n",
    "            Generate the full query for sentiment analysis task\n",
    "        '''\n",
    "        general_instruction = self.generate_general_instruction(batch_size)\n",
    "        \n",
    "        cot_instruction = ''\n",
    "        if self.cot:\n",
    "            cot_instruction = self.generate_cot_instruction()\n",
    "        \n",
    "        final_instruction = self.generate_final_instruction(text_batch)\n",
    "\n",
    "        if self.few_shot:\n",
    "            instructions_query = [\n",
    "                {\n",
    "                    \"role\":\"user\",\n",
    "                    \"content\":general_instruction + cot_instruction,\n",
    "                }\n",
    "            ]\n",
    "            few_shot_examples = self.generate_few_shot_examples()\n",
    "            review_query = [\n",
    "                {\n",
    "                    \"role\":\"user\",\n",
    "                    \"content\":final_instruction,\n",
    "                }\n",
    "            ]\n",
    "            return instructions_query + few_shot_examples + review_query\n",
    "        else:\n",
    "            return [\n",
    "                {\n",
    "                    \"role\":\"user\",\n",
    "                    \"content\":general_instruction + cot_instruction + final_instruction,\n",
    "                }\n",
    "            ]\n",
    "        \n",
    "    def generate_output_schema(self) -> dict:\n",
    "        '''\n",
    "            Generate the output schema for sentiment analysis task\n",
    "        '''\n",
    "\n",
    "        if self.binary:\n",
    "            sentiment_enum = [\"0\", \"1\"]\n",
    "        else:\n",
    "            sentiment_enum = [\"0\", \"1\", \"2\", \"3\", \"4\"]\n",
    "\n",
    "        response_format = {\n",
    "            'type': \"json_schema\",\n",
    "            'json_schema': {\n",
    "                'name': \"product_review\",\n",
    "                'schema': {\n",
    "                    'type': \"object\",\n",
    "                    'properties': {\n",
    "                    'index': { 'type': \"string\" },\n",
    "                    'sentiment_rating': { \n",
    "                        'type': \"string\",\n",
    "                        'enum': sentiment_enum\n",
    "                        },\n",
    "                    },\n",
    "                'required': [\"index\", \"sentiment_rating\"],\n",
    "                'additionalProperties': False\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        return response_format\n",
    "    \n",
    "    def  generate_system_query(self) -> str:\n",
    "        '''\n",
    "            Create system instruction for sentiment analysis task\n",
    "        '''\n",
    "        if self.binary:\n",
    "            content = \"2.  **Content:** For each review, provide the sentiment as a string representation of an integer: either 0 (negative) or 1 (positive).\"\n",
    "        else:\n",
    "            content = \"2.  **Content:** For each review, provide the sentiment as a string representation of an integer from 0 (very negative) to 4 (very positive).\"\n",
    "        system_instruction = f\"\"\"\n",
    "            You are an expert sentiment analyst for Amazon product reviews. Your task is to process a batch of reviews and output the results as a single JSON object.\n",
    "            1.  **Indexing:** The 'reviews' array MUST contain the same number of items as the input reviews, and each item's 'index' MUST correspond exactly to the review's sequential position.\n",
    "            {content}\n",
    "            3.  **No Explanation:** DO NOT include any introductory text, explanation, or any Markdown fences (like ```json or ```) outside of the required JSON object.\n",
    "            \"\"\"\n",
    "        \n",
    "        system_query = [{\"role\": \"system\", \"content\": system_instruction}]\n",
    "        return system_query\n",
    "\n",
    "def predict_sentiments_groq(sample_text: list[str]\n",
    "                            , chunk_size: int\n",
    "                            , model: str\n",
    "                            , few_shot: bool=False\n",
    "                            , cot: bool=False\n",
    "                            , binary: bool=False\n",
    "                            , response_format: bool=True) -> list[dict]:\n",
    "    '''\n",
    "        Predict sentiment ratings for a list of reviews using Gemini API.\n",
    "    '''\n",
    "    client_groq = Groq()\n",
    "    all_predictions = []\n",
    "    responses = []\n",
    "\n",
    "     # chunk prediction to avoid rate limiting and output size inconsistency\n",
    "    for i in range(0, len(sample_text), chunk_size):\n",
    "        # Get a slice of the reviews\n",
    "        batch = sample_text[i:i + chunk_size]\n",
    "        text_batch = ''\n",
    "        for ind, text in enumerate(batch):\n",
    "            # Use a clear XML tag for each review and its index\n",
    "            text_batch += f\"<review id='{i + ind}'>{text}</review>\\n\"\n",
    "        \n",
    "        \n",
    "        # format prompt, instructions, and output schema\n",
    "        prompt_generator = PromptGenerator(few_shot=few_shot, cot=cot, binary=binary)\n",
    "        query = prompt_generator.gen_query(batch_size=len(batch), text_batch=text_batch)\n",
    "        system_query = prompt_generator.generate_system_query()\n",
    "\n",
    "        # only llama 4 and gpt oss models support response schema\n",
    "        if response_format:\n",
    "            response_format = prompt_generator.generate_output_schema()\n",
    "        messages = system_query + query\n",
    "        \n",
    "        # try to generate content if error occurs wait and retry\n",
    "        try_count = 0\n",
    "        while try_count < 10:\n",
    "            try:\n",
    "                try_count += 1\n",
    "                if response_format:\n",
    "                    chat_completion = client_groq.chat.completions.create(\n",
    "                        messages=messages,\n",
    "                        response_format=response_format,\n",
    "                        model=model,\n",
    "                    )\n",
    "                else:\n",
    "                    chat_completion = client_groq.chat.completions.create(\n",
    "                        messages=messages,\n",
    "                        model=model,\n",
    "                    )\n",
    "                break  # Exit the retry loop if successful\n",
    "            except Exception as e:\n",
    "                print(f\"Error occurred: {e}. Retrying in 60 seconds...\")\n",
    "                time.sleep(60)   \n",
    "\n",
    "        # Extract the content from the response and store it for manual inspection if needed\n",
    "        content = chat_completion.choices[0].message.content\n",
    "        responses.append(content)\n",
    "\n",
    "\n",
    "        # Parse the response content. \n",
    "        # Without prompt formatting, we need to extract the JSON part from the response by text cleaning.\n",
    "        try:\n",
    "            if response_format:\n",
    "                response_data = json.loads(content)\n",
    "            else:\n",
    "                response_data = json.loads(content.split('</think>')[-1].replace('```json', '').replace('```', '').strip())\n",
    "            # response_data = json.loads(c)\n",
    "            # response_data = response_data['reviews']\n",
    "\n",
    "            # save predictions\n",
    "            key = list(response_data.keys())[0]\n",
    "            predictons = response_data[key]\n",
    "            print(len(predictons))\n",
    "            \n",
    "            all_predictions.extend(predictons)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(chat_completion.choices[0].message.content)\n",
    "            print(f\"Error parsing response: {e}\")\n",
    "            continue\n",
    "        \n",
    "        time.sleep(60)  # To avoid rate limiting\n",
    "\n",
    "    return all_predictions, responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e487d575",
   "metadata": {},
   "source": [
    "## 2. Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f73ec4e",
   "metadata": {},
   "source": [
    "## meta-llama/llama-4-maverick-17b-128e-instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68041d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_llama = pd.read_parquet(\"data/test_10k_5.parquet\")\n",
    "sample_text = test_llama.text.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d14e5d3",
   "metadata": {},
   "source": [
    "### 0-Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297412c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = \"meta-llama/llama-4-maverick-17b-128e-instruct\"\n",
    "chunk_size = 50\n",
    "\n",
    "all_predictions, all_responses = predict_sentiments_groq(sample_text=sample_text, \n",
    "                                         chunk_size=chunk_size, \n",
    "                                         model=model,\n",
    "                                         few_shot=False,\n",
    "                                         cot=False,\n",
    "                                         binary=False,\n",
    "                                         response_format=True) \n",
    "test_llama['pred_0s_2'] = pd.DataFrame(all_predictions)['sentiment_rating'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9192fec3",
   "metadata": {},
   "source": [
    "### Few-Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5952b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.746)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = \"meta-llama/llama-4-maverick-17b-128e-instruct\"\n",
    "chunk_size = 60\n",
    "all_predictions, all_responses = predict_sentiments_groq(sample_text=sample_text, \n",
    "                                          chunk_size=chunk_size, \n",
    "                                          model=model, \n",
    "                                          few_shot=True, \n",
    "                                          cot=False, \n",
    "                                          binary=False,\n",
    "                                          response_format=True) \n",
    "\n",
    "test_llama['pred_5s'] = pd.DataFrame(all_predictions)['sentiment_rating'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c119955",
   "metadata": {},
   "source": [
    "### Chain-of-Thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be532ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.739)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = \"meta-llama/llama-4-maverick-17b-128e-instruct\"\n",
    "chunk_size = 60\n",
    "all_predictions, all_responses = predict_sentiments_groq(sample_text=sample_text, \n",
    "                                          chunk_size=chunk_size, \n",
    "                                          model=model, \n",
    "                                          few_shot=False, \n",
    "                                          cot=True, \n",
    "                                          binary=False,\n",
    "                                          response_format=True) \n",
    "\n",
    "test_llama['pred_cot'] = pd.DataFrame(all_predictions)['sentiment_rating'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1aa5ee",
   "metadata": {},
   "source": [
    "### Chain-of-thought + Few-Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83e1964e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "model = \"meta-llama/llama-4-maverick-17b-128e-instruct\"\n",
    "chunk_size = 60\n",
    "all_predictions, all_responses = predict_sentiments_groq(sample_text=sample_text, \n",
    "                                          chunk_size=chunk_size, \n",
    "                                          model=model, \n",
    "                                          few_shot=True, \n",
    "                                          cot=True, \n",
    "                                          binary=False,\n",
    "                                          response_format=True) \n",
    "test_llama['pred_cot_5s'] = pd.DataFrame(all_predictions)['sentiment_rating'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff37face",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_llama.to_csv(\"results/test_5_llm_llama_4_128e.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e2bdd8",
   "metadata": {},
   "source": [
    "## openai/gpt-oss-120b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ddc27eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gpt = pd.read_parquet(\"data/test_10k_5.parquet\")\n",
    "sample_text = test_gpt.text.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705696bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "## GPT-oss\n",
    "model = \"openai/gpt-oss-120b\"\n",
    "chunk_size = 50\n",
    "\n",
    "all_predictions = predict_sentiments_groq(sample_text=sample_text, \n",
    "                                         chunk_size=chunk_size, \n",
    "                                         model=model,\n",
    "                                         few_shot=False,\n",
    "                                         cot=False,\n",
    "                                         binary=False,\n",
    "                                         response_format=True) \n",
    "test_gpt['pred_gpt_0s'] = pd.DataFrame(all_predictions)['sentiment_rating'].astype(int)\n",
    "test_gpt.to_csv(\"results/test_5_llm_gpt_oss_120b.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f6f948",
   "metadata": {},
   "source": [
    "### Few-Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae868b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.704)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = \"openai/gpt-oss-120b\"\n",
    "chunk_size = 50\n",
    "\n",
    "all_predictions, all_responses = predict_sentiments_groq(sample_text=sample_text, \n",
    "                                         chunk_size=chunk_size, \n",
    "                                         model=model,\n",
    "                                         few_shot=True,\n",
    "                                         cot=False,\n",
    "                                         binary=False,\n",
    "                                         response_format=True) \n",
    "test_gpt['pred_gpt_5s'] = pd.DataFrame(all_predictions)['sentiment_rating'].astype(int)\n",
    "test_gpt.to_csv(\"results/test_5_llm_gpt_oss_120b.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff147156",
   "metadata": {},
   "source": [
    "### Chain-of-thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a66c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "model = \"openai/gpt-oss-120b\"\n",
    "chunk_size = 50\n",
    "\n",
    "all_predictions, all_responses = predict_sentiments_groq(sample_text=sample_text, \n",
    "                                         chunk_size=chunk_size, \n",
    "                                         model=model,\n",
    "                                         few_shot=False,\n",
    "                                         cot=True,\n",
    "                                         binary=False,\n",
    "                                         response_format=True) \n",
    "test_gpt['pred_gpt_cot'] = pd.DataFrame(all_predictions)['sentiment_rating'].astype(int)\n",
    "test_gpt.to_csv(\"results/test_5_llm_gpt_oss_120b.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75536296",
   "metadata": {},
   "source": [
    "### Chain-of-thought + Few-Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8f57e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "model = \"openai/gpt-oss-120b\"\n",
    "chunk_size = 50\n",
    "\n",
    "all_predictions, all_responses = predict_sentiments_groq(sample_text=sample_text, \n",
    "                                         chunk_size=chunk_size, \n",
    "                                         model=model,\n",
    "                                         few_shot=True,\n",
    "                                         cot=True,\n",
    "                                         binary=False,\n",
    "                                         response_format=True)\n",
    "\n",
    "test_gpt['pred_gpt_cot_5s'] = pd.DataFrame(all_predictions)['sentiment_rating'].astype(int)\n",
    "test_gpt.to_csv(\"results/test_5_llm_gpt_oss_120b.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe3b77f",
   "metadata": {},
   "source": [
    "## qwen/qwen3-32b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2392950",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_qwen = pd.read_parquet(\"data/test_10k_5.parquet\") # Note that all of the test data for 5-class model are the same\n",
    "sample_text = test_qwen.text.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f284a1",
   "metadata": {},
   "source": [
    "### 0-Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5e0ee80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "model = \"qwen/qwen3-32b\"\n",
    "chunk_size = 60\n",
    "\n",
    "all_predictions, all_responses = predict_sentiments_groq(sample_text=sample_text, \n",
    "                                         chunk_size=chunk_size, \n",
    "                                         model=model,\n",
    "                                         few_shot=False,\n",
    "                                         cot=False,\n",
    "                                         binary=False,\n",
    "                                         response_format=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ad2a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sometimes the response is not properly formatted, so we need to do some text cleaning\n",
    "all_pred = pd.DataFrame()\n",
    "for i in all_responses:\n",
    "    content = i.split('</think>')[-1].replace('```json', '').replace('```', '').strip()\n",
    "    json_content = json.loads(content)\n",
    "    try:\n",
    "        df = pd.DataFrame(json_content['reviews'])\n",
    "    except Exception as e:\n",
    "        df = pd.DataFrame(json_content)\n",
    "        # break\n",
    "    all_pred = pd.concat([all_pred, df], ignore_index=True)\n",
    "\n",
    "if 'sentiment_rate' in all_pred.columns:\n",
    "    all_pred['sentiment_rating'] = np.where(all_pred['sentiment_rating'].notna(),\n",
    "                                        all_pred['sentiment_rating'],\n",
    "                                            all_pred['sentiment_rate'])\n",
    "\n",
    "test_qwen['pred_qwen3_0s'] = all_pred['sentiment_rating'].astype(int)\n",
    "test_qwen.to_csv(\"results/test_5_llm_qwen3_32b.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf20abb",
   "metadata": {},
   "source": [
    "### Few-Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa3c686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "<think>\n",
      "Okay, let's tackle this batch of reviews. First, I need to go through each one and determine the sentiment on a scale from 0 to 4. Let's start with review 300. The user mentions a part that popped off but got it back on and likes the cooling effect and massage feel. There's a mix of negative and positive points, but overall, the positive aspects seem to outweigh. Maybe a 3?\n",
      "\n",
      "Review 301 is positive, talking about the scent being nice and lasting. The user prefers it over expensive ones. That sounds like a 4. \n",
      "\n",
      "Review 302 lists three good points without negative. Definitely a 4. \n",
      "\n",
      "Review 303 is a strong positive with the user being happy and mentioning quality. 4 makes sense here. \n",
      "\n",
      "Review 304 says the girlfriend loves them and they're worth the price. Positive, so 4. \n",
      "\n",
      "Review 305 praises the tool for dance classes and effectiveness. 4 again. \n",
      "\n",
      "Review 306 expresses disappointment Sally's doesn't sell them. That's a 3, maybe slightly negative but still positive. \n",
      "\n",
      "Review 307 is neutral with \"couldn't see the result yet.\" Maybe a 2 or 3? The user is tentative. \n",
      "\n",
      "Review 308 is positive about cones, nice burn time, packaging. 4 points. \n",
      "\n",
      "Review 309 was disappointed; the product didn't meet expectations. That's a 0 or 1. Maybe 1. \n",
      "\n",
      "Review 310 is positive with \"love the heart diamond.\" 4. \n",
      "\n",
      "Review 311 praises the exfoliating brushes. 4. \n",
      "\n",
      "Review 312 mentions it's cute but only for certain hair. Maybe 3. \n",
      "\n",
      "Review 313 is negative due to Chinese origins and safety concerns. 0. \n",
      "\n",
      "Review 314 is very enthusiastic, repeated exclamation. 4. \n",
      "\n",
      "Review 315 says classic Camay, good product. 4. \n",
      "\n",
      "Review 316 high quality, recommend. 4. \n",
      "\n",
      "Review 317 is positive despite a bit pricey. 3. \n",
      "\n",
      "Review 318 recommends for skin issues. 4. \n",
      "\n",
      "Review 319 positive about the massage effect. 3. \n",
      "\n",
      "Review 320 negative about the elastic not holding. 1. \n",
      "\n",
      "Review 321 is positive. 4. \n",
      "\n",
      "Review 322 mixed, but overall good for the price. 3. \n",
      "\n",
      "Review 323 negative due to scent issues. 1. \n",
      "\n",
      "Review 324 colors not as expected. 1. \n",
      "\n",
      "Review 325 didn't work for lashes. 0. \n",
      "\n",
      "Review 326 small but okay for price. 2. \n",
      "\n",
      "Review 327 practical use, okay. 2. \n",
      "\n",
      "Review 328 positive, holy grail product. 4. \n",
      "\n",
      "Review 329 neutral. 2. \n",
      "\n",
      "Review 330 loved for 3 years. 4. \n",
      "\n",
      "Review 331 helpful for recovery. 4. \n",
      "\n",
      "Review 332 simple negative. 0. \n",
      "\n",
      "Review 333 too small. 1. \n",
      "\n",
      "Review 334 product fails to work. 0. \n",
      "\n",
      "Review 335 positive about scunchies. 4. \n",
      "\n",
      "Review 336 product caused color issues. 1. \n",
      "\n",
      "Review 337 very good. 3. \n",
      "\n",
      "Review 338 okay for price. 2. \n",
      "\n",
      "Review 339 easy to use, effective. 4. \n",
      "\n",
      "Review 340 doesn't set well. 1. \n",
      "\n",
      "Review 341 strong positive, mentions SEPHORA not having it. 4. \n",
      "\n",
      "Review 342 mixed, but initial positive followed by negative. Maybe 2. \n",
      "\n",
      "Review 343 praises the turban. 4. \n",
      "\n",
      "Review 344 poor quality wig. 0. \n",
      "\n",
      "Review 345 favorite perfume. 4. \n",
      "\n",
      "Review 346 uses in different ways. 3. \n",
      "\n",
      "Review 347 best natural deodorant. 4. \n",
      "\n",
      "Review 348 returned due to inconsistency. 1. \n",
      "\n",
      "Review 349 economical. 2. \n",
      "\n",
      "Review 350 cat hates it. 0. \n",
      "\n",
      "Review 351 sticky, slides. 0. \n",
      "\n",
      "Review 352 product lasts long, positive. 4. \n",
      "\n",
      "Review 353 gift idea. 4. \n",
      "\n",
      "Review 354 one component bad, others good. 2. \n",
      "\n",
      "Review 355 looks good, holds up. 4. \n",
      "\n",
      "Review 356 expensive. 1. \n",
      "\n",
      "Review 357 positive, will repurchase. 4. \n",
      "\n",
      "Review 358 received in bad condition. 0. \n",
      "\n",
      "Review 359 good for specific use. 3. \n",
      "\n",
      "Need to make sure each index from 300 to 359 is mapped correctly with the correct sentiment. Let me double-check each one for accuracy. Some might be tricky, but overall, I think the initial assessments are okay. Now, compiling everything into the required JSON format.\n",
      "</think>\n",
      "\n",
      "[{\"index\":\"300\",\"sentiment_rating\":\"3\"},{\"index\":\"301\",\"sentiment_rating\":\"4\"},{\"index\":\"302\",\"sentiment_rating\":\"4\"},{\"index\":\"303\",\"sentiment_rating\":\"4\"},{\"index\":\"304\",\"sentiment_rating\":\"4\"},{\"index\":\"305\",\"sentiment_rating\":\"4\"},{\"index\":\"306\",\"sentiment_rating\":\"3\"},{\"index\":\"307\",\"sentiment_rating\":\"2\"},{\"index\":\"308\",\"sentiment_rating\":\"4\"},{\"index\":\"309\",\"sentiment_rating\":\"1\"},{\"index\":\"310\",\"sentiment_rating\":\"4\"},{\"index\":\"311\",\"sentiment_rating\":\"4\"},{\"index\":\"312\",\"sentiment_rating\":\"3\"},{\"index\":\"313\",\"sentiment_rating\":\"0\"},{\"index\":\"314\",\"sentiment_rating\":\"4\"},{\"index\":\"315\",\"sentiment_rating\":\"4\"},{\"index\":\"316\",\"sentiment_rating\":\"4\"},{\"index\":\"317\",\"sentiment_rating\":\"3\"},{\"index\":\"318\",\"sentiment_rating\":\"4\"},{\"index\":\"319\",\"sentiment_rating\":\"3\"},{\"index\":\"320\",\"sentiment_rating\":\"1\"},{\"index\":\"321\",\"sentiment_rating\":\"4\"},{\"index\":\"322\",\"sentiment_rating\":\"3\"},{\"index\":\"323\",\"sentiment_rating\":\"1\"},{\"index\":\"324\",\"sentiment_rating\":\"1\"},{\"index\":\"325\",\"sentiment_rating\":\"0\"},{\"index\":\"326\",\"sentiment_rating\":\"2\"},{\"index\":\"327\",\"sentiment_rating\":\"2\"},{\"index\":\"328\",\"sentiment_rating\":\"4\"},{\"index\":\"329\",\"sentiment_rating\":\"2\"},{\"index\":\"330\",\"sentiment_rating\":\"4\"},{\"index\":\"331\",\"sentiment_rating\":\"4\"},{\"index\":\"332\",\"sentiment_rating\":\"0\"},{\"index\":\"333\",\"sentiment_rating\":\"1\"},{\"index\":\"334\",\"sentiment_rating\":\"0\"},{\"index\":\"335\",\"sentiment_rating\":\"4\"},{\"index\":\"336\",\"sentiment_rating\":\"1\"},{\"index\":\"337\",\"sentiment_rating\":\"3\"},{\"index\":\"338\",\"sentiment_rating\":\"2\"},{\"index\":\"339\",\"sentiment_rating\":\"4\"},{\"index\":\"340\",\"sentiment_rating\":\"1\"},{\"index\":\"341\",\"sentiment_rating\":\"4\"},{\"index\":\"342\",\"sentiment_rating\":\"2\"},{\"index\":\"343\",\"sentiment_rating\":\"4\"},{\"index\":\"344\",\"sentiment_rating\":\"0\"},{\"index\":\"345\",\"sentiment_rating\":\"4\"},{\"index\":\"346\",\"sentiment_rating\":\"3\"},{\"index\":\"347\",\"sentiment_rating\":\"4\"},{\"index\":\"348\",\"sentiment_rating\":\"1\"},{\"index\":\"349\",\"sentiment_rating\":\"2\"},{\"index\":\"350\",\"sentiment_rating\":\"0\"},{\"index\":\"351\",\"sentiment_rating\":\"0\"},{\"index\":\"352\",\"sentiment_rating\":\"4\"},{\"index\":\"353\",\"sentiment_rating\":\"4\"},{\"index\":\"354\",\"sentiment_rating\":\"2\"},{\"index\":\"355\",\"sentiment_rating\":\"4\"},{\"index\":\"356\",\"sentiment_rating\":\"1\"},{\"index\":\"357\",\"sentiment_rating\":\"4\"},{\"index\":\"358\",\"sentiment_rating\":\"0\"},{\"index\":\"359\",\"sentiment_rating\":\"3\"}]\n",
      "Error parsing response: 'list' object has no attribute 'keys'\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "model = \"qwen/qwen3-32b\"\n",
    "chunk_size = 60\n",
    "\n",
    "all_predictions, all_responses = predict_sentiments_groq(sample_text=sample_text, \n",
    "                                         chunk_size=chunk_size, \n",
    "                                         model=model,\n",
    "                                         few_shot=True,\n",
    "                                         cot=False,\n",
    "                                         binary=False,\n",
    "                                         response_format=False) \n",
    "\n",
    "# Sometimes the response is not properly formatted, so we need to do some text cleaning\n",
    "all_pred = pd.DataFrame()\n",
    "for i in all_responses:\n",
    "    content = i.split('</think>')[-1].replace('```json', '').replace('```', '').strip()\n",
    "    json_content = json.loads(content)\n",
    "    try:\n",
    "        df = pd.DataFrame(json_content['reviews'])\n",
    "    except Exception as e:\n",
    "        df = pd.DataFrame(json_content)\n",
    "        # break\n",
    "    all_pred = pd.concat([all_pred, df], ignore_index=True)\n",
    "\n",
    "if 'sentiment_rate' in all_pred.columns:\n",
    "    all_pred['sentiment_rating'] = np.where(all_pred['sentiment_rating'].notna(),\n",
    "                                        all_pred['sentiment_rating'],\n",
    "                                            all_pred['sentiment_rate'])\n",
    "\n",
    "test_qwen['pred_qwen3_5s'] = all_pred['sentiment_rating'].astype(int)\n",
    "test_qwen.to_csv(\"results/test_5_llm_qwen3_32b.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0eca99",
   "metadata": {},
   "source": [
    "### Chain-of-thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821f02ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred: Connection error.. Retrying in 60 seconds...\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.654)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = \"qwen/qwen3-32b\"\n",
    "chunk_size = 60\n",
    "\n",
    "all_predictions, all_responses = predict_sentiments_groq(sample_text=sample_text, \n",
    "                                         chunk_size=chunk_size, \n",
    "                                         model=model,\n",
    "                                         few_shot=False,\n",
    "                                         cot=True,\n",
    "                                         binary=False,\n",
    "                                         response_format=False) \n",
    "\n",
    "# Sometimes the response is not properly formatted, so we need to do some text cleaning\n",
    "all_pred = pd.DataFrame()\n",
    "for i in all_responses:\n",
    "    content = i.split('</think>')[-1].replace('```json', '').replace('```', '').strip()\n",
    "    json_content = json.loads(content)\n",
    "    try:\n",
    "        df = pd.DataFrame(json_content['reviews'])\n",
    "    except Exception as e:\n",
    "        df = pd.DataFrame(json_content)\n",
    "        # break\n",
    "    all_pred = pd.concat([all_pred, df], ignore_index=True)\n",
    "\n",
    "if 'sentiment_rate' in all_pred.columns:\n",
    "    all_pred['sentiment_rating'] = np.where(all_pred['sentiment_rating'].notna(),\n",
    "                                        all_pred['sentiment_rating'],\n",
    "                                            all_pred['sentiment_rate'])\n",
    "\n",
    "test_qwen['pred_qwen3_cot'] = all_pred['sentiment_rating'].astype(int)\n",
    "test_qwen.to_csv(\"results/test_5_llm_qwen3_32b.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab07bab8",
   "metadata": {},
   "source": [
    "### Chain-of-thought + Few-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88a3b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "<think>\n",
      "Okay, I need to process these Amazon reviews and assign each a sentiment rating from 0 to 4. Let me start by going through each review one by one, using the CoT steps as instructed.\n",
      "\n",
      "Starting with review 300. The user mentions that the product popped off with little force initially but was able to fix it. There are positive aspects like it stays cold, feels good for facial massage, and works after being fixed. The main sentiment is mixed, but since they continue using it and mention benefits, I'll rate it a 3.\n",
      "\n",
      "Review 301 talks about a nice smell that's not overpowering and a good value compared to expensive products. The sentiment is positive. Rating 4.\n",
      "\n",
      "Review 302 is three positive points about the product's performance. Definitely positive. Rating 4.\n",
      "\n",
      "Review 303 praises the chapstick for lasting, high melting point, quality, and value. Positive. Rating 4.\n",
      "\n",
      "Review 304 mentions the girlfriend loves them and they're worth the price. Positive. Rating 4.\n",
      "\n",
      "Review 305 is about the best bun tool, works well for dance class. Positive. Rating 4.\n",
      "\n",
      "Review 306 is a positive note about the product being awesome but not available where they used to buy them. Slight negative about availability but overall positive towards the product. Rating 3.\n",
      "\n",
      "Review 307 mentions the cream is good but results aren't seen yet. So, uncertain but positive so far. Rating 2.\n",
      "\n",
      "Review 308 praises the cones and packaging. Positive. Rating 4.\n",
      "\n",
      "Review 309 has a minor disappointment about not getting the hologram effect but still finds it lovely. Mixed, leaning neutral. Rating 2.\n",
      "\n",
      "Review 310 is a short positive. Rating 4.\n",
      "\n",
      "Review 311 talks about good quality brushes. Positive. Rating 4.\n",
      "\n",
      "Review 312 is positive about the hair clip. Rating 4.\n",
      "\n",
      "Review 313 is a strong negative about the product being made in China and safety concerns. Rating 0.\n",
      "\n",
      "Review 314 is very enthusiastic and positive, using exclamation marks. Rating 4.\n",
      "\n",
      "Review 315 praises the soap. Positive. Rating 4.\n",
      "\n",
      "Review 316 is positive. Rating 4.\n",
      "\n",
      "Review 317 mentions being a bit pricey but worth it. Slightly positive. Rating 3.\n",
      "\n",
      "Review 318 is a detailed positive. Rating 4.\n",
      "\n",
      "Review 319 is positive. Rating 4.\n",
      "\n",
      "Review 320 is a strong negative. Rating 0.\n",
      "\n",
      "Review 321 is a glowing positive. Rating 4.\n",
      "\n",
      "Review 322 mentions some negatives but overall likes the price. Mixed, maybe a 2.\n",
      "\n",
      "Review 323 is a negative due to strong fragrance. Rating 1.\n",
      "\n",
      "Review 324 is a negative due to color mismatch. Rating 1.\n",
      "\n",
      "Review 325 is a negative. Rating 0.\n",
      "\n",
      "Review 326 is a neutral comment. Rating 2.\n",
      "\n",
      "Review 327 is a neutral, just states usage. Rating 1.\n",
      "\n",
      "Review 328 is positive. Rating 4.\n",
      "\n",
      "Review 329 is \"Is ok\" which is neutral. Rating 2.\n",
      "\n",
      "Review 330 is positive. Rating 4.\n",
      "\n",
      "Review 331 mentions helpful during recovery. Positive. Rating 4.\n",
      "\n",
      "Review 332 is a clear negative. Rating 0.\n",
      "\n",
      "Review 333 is negative about size. Rating 1.\n",
      "\n",
      "Review 334 is a strong negative. Rating 0.\n",
      "\n",
      "Review 335 is positive with emojis. Rating 4.\n",
      "\n",
      "Review 336 is negative about appearance issues. Rating 1.\n",
      "\n",
      "Review 337 is \"Very good\" which is positive. Rating 4.\n",
      "\n",
      "Review 338 is a neutral but mentions value. Rating 3.\n",
      "\n",
      "Review 339 is positive about effectiveness. Rating 4.\n",
      "\n",
      "Review 340 is negative. Rating 0.\n",
      "\n",
      "Review 341 is enthusiastic, mentions feeling in love. Rating 4.\n",
      "\n",
      "Review 342 has a positive start but a strong negative end about quality. Mixed, but more negative. Rating 1.\n",
      "\n",
      "Review 343 is a positive. Rating 4.\n",
      "\n",
      "Review 344 is a negative. Rating 0.\n",
      "\n",
      "Review 345 is a positive. Rating 4.\n",
      "\n",
      "Review 346 is a positive use case. Rating 4.\n",
      "\n",
      "Review 347 is a positive about the deodorant. Rating 4.\n",
      "\n",
      "Review 348 is a negative about inconsistency. Rating 1.\n",
      "\n",
      "Review 349 is positive about economy. Rating 3.\n",
      "\n",
      "Review 350 is a negative about the cat. Rating 0.\n",
      "\n",
      "Review 351 is a negative. Rating 0.\n",
      "\n",
      "Review 352 is positive about value. Rating 4.\n",
      "\n",
      "Review 353 is neutral/gift idea. Rating 2.\n",
      "\n",
      "Review 354 mentions a negative about the smelly blenders. Rating 2.\n",
      "\n",
      "Review 355 is positive. Rating 4.\n",
      "\n",
      "Review 356 is a complaint about pricing. Rating 1.\n",
      "\n",
      "Review 357 is positive. Rating 4.\n",
      "\n",
      "Review 358 is a negative about packaging and size. Rating 0.\n",
      "\n",
      "Review 359 is a warning about usage. Rating 2.\n",
      "</think>\n",
      "\n",
      "[\n",
      "  {\"index\": \"300\", \"sentiment_rating\": \"3\"},\n",
      "  {\"index\": \"301\", \"sentiment_rating\": \"4\"},\n",
      "  {\"index\": \"302\", \"sentiment_rating\": \"4\"},\n",
      "  {\"index\": \"303\", \"sentiment_rating\": \"4\"},\n",
      "  {\"index\": \"304\", \"sentiment_rating\": \"4\"},\n",
      "  {\"index\": \"305\", \"sentiment_rating\": \"4\"},\n",
      "  {\"index\": \"306\", \"sentiment_rating\": \"3\"},\n",
      "  {\"index\": \"307\", \"sentiment_rating\": \"2\"},\n",
      "  {\"index\": \"308\", \"sentiment_rating\": \"4\"},\n",
      "  {\"index\": \"309\", \"sentiment_rating\": \"2\"},\n",
      "  {\"index\": \"310\", \"sentiment_rating\": \"4\"},\n",
      "  {\"index\": \"311\", \"sentiment_rating\": \"4\"},\n",
      "  {\"index\": \"312\", \"sentiment_rating\": \"4\"},\n",
      "  {\"index\": \"313\", \"sentiment_rating\": \"0\"},\n",
      "  {\"index\": \"314\", \"sentiment_rating\": \"4\"},\n",
      "  {\"index\": \"315\", \"sentiment_rating\": \"4\"},\n",
      "  {\"index\": \"316\", \"sentiment_rating\": \"4\"},\n",
      "  {\"index\": \"317\", \"sentiment_rating\": \"3\"},\n",
      "  {\"index\": \"318\", \"sentiment_rating\": \"4\"},\n",
      "  {\"index\": \"319\", \"sentiment_rating\": \"4\"},\n",
      "  {\"index\": \"320\", \"sentiment_rating\": \"0\"},\n",
      "  {\"index\": \"321\", \"sentiment_rating\": \"4\"},\n",
      "  {\"index\": \"322\", \"sentiment_rating\": \"2\"},\n",
      "  {\"index\": \"323\", \"sentiment_rating\": \"1\"},\n",
      "  {\"index\": \"324\", \"sentiment_rating\": \"1\"},\n",
      "  {\"index\": \"325\", \"sentiment_rating\": \"0\"},\n",
      "  {\"index\": \"326\", \"sentiment_rating\": \"2\"},\n",
      "  {\"index\": \"327\", \"sentiment_rating\": \"1\"},\n",
      "  {\"index\": \"328\", \"sentiment_rating\": \"4\"},\n",
      "  {\"index\": \"329\", \"sentiment_rating\": \"2\"},\n",
      "  {\"index\": \"330\", \"sentiment_rating\": \"4\"},\n",
      "  {\"index\": \"331\", \"sentiment_rating\": \"4\"},\n",
      "  {\"index\": \"332\", \"sentiment_rating\": \"0\"},\n",
      "  {\"index\": \"333\", \"sentiment_rating\": \"1\"},\n",
      "  {\"index\": \"334\", \"sentiment_rating\": \"0\"},\n",
      "  {\"index\": \"335\", \"sentiment_rating\": \"4\"},\n",
      "  {\"index\": \"336\", \"sentiment_rating\": \"1\"},\n",
      "  {\"index\": \"337\", \"sentiment_rating\": \"4\"},\n",
      "  {\"index\": \"338\", \"sentiment_rating\": \"3\"},\n",
      "  {\"index\": \"339\", \"sentiment_rating\": \"4\"},\n",
      "  {\"index\": \"340\", \"sentiment_rating\": \"0\"},\n",
      "  {\"index\": \"341\", \"sentiment_rating\": \"4\"},\n",
      "  {\"index\": \"342\", \"sentiment_rating\": \"1\"},\n",
      "  {\"index\": \"343\", \"sentiment_rating\": \"4\"},\n",
      "  {\"index\": \"344\", \"sentiment_rating\": \"0\"},\n",
      "  {\"index\": \"345\", \"sentiment_rating\": \"4\"},\n",
      "  {\"index\": \"346\", \"sentiment_rating\": \"4\"},\n",
      "  {\"index\": \"347\", \"sentiment_rating\": \"4\"},\n",
      "  {\"index\": \"348\", \"sentiment_rating\": \"1\"},\n",
      "  {\"index\": \"349\", \"sentiment_rating\": \"3\"},\n",
      "  {\"index\": \"350\", \"sentiment_rating\": \"0\"},\n",
      "  {\"index\": \"351\", \"sentiment_rating\": \"0\"},\n",
      "  {\"index\": \"352\", \"sentiment_rating\": \"4\"},\n",
      "  {\"index\": \"353\", \"sentiment_rating\": \"2\"},\n",
      "  {\"index\": \"354\", \"sentiment_rating\": \"2\"},\n",
      "  {\"index\": \"355\", \"sentiment_rating\": \"4\"},\n",
      "  {\"index\": \"356\", \"sentiment_rating\": \"1\"},\n",
      "  {\"index\": \"357\", \"sentiment_rating\": \"4\"},\n",
      "  {\"index\": \"358\", \"sentiment_rating\": \"0\"},\n",
      "  {\"index\": \"359\", \"sentiment_rating\": \"2\"}\n",
      "]\n",
      "Error parsing response: 'list' object has no attribute 'keys'\n",
      "60\n",
      "<think>\n",
      "Okay, let's tackle these reviews one by one. Starting with review 420: \"Very sharp, very delicate, a full range, especially pointed nail clippers, small but can cut toenails, I like very much.\" The user is mentioning positive aspects like sharpness and versatility, especially with toenails. The sentiment seems positive, so probably a 4.\n",
      "\n",
      "Review 421: The user loves the table cover, mentions it's soft, fits well, has room for shrinkage, and no straps to lose shape. All positives here, so a 4 makes sense.\n",
      "\n",
      "Review 422: \"As advertised, no issues.\" Neutral but positive. Since there's no complaint, maybe a 3 or 4. Since it's just a confirmation, maybe a 4 as it's positive.\n",
      "\n",
      "Review 423: The parent is happy the child engages with the toothbrush. Lots of positive words like \"happy\", \"loves\", \"very happy\". Definitely a 4.\n",
      "\n",
      "Review 424: User likes the butter for deodorant, mentions it's good and the price is great. Positive aspects, so a 4.\n",
      "\n",
      "Review 425: The product is too small and low quality. The negative points are clear, so a 1 or 0. Since they asked for it bigger, maybe a 1.\n",
      "\n",
      "Review 426: \"Perfect\" is a strong positive, so 4.\n",
      "\n",
      "Review 427: \"Great\" as well, likely 4.\n",
      "\n",
      "Review 428: Saved money and is worth it. Definitely positive, 4.\n",
      "\n",
      "Review 429: \"Light weight.\" Neutral or slightly negative? Maybe 2. If it's a positive (for something like a backpack), but if it's a negative (like a heavy item needing to be heavy), but the review is just \"light weight,\" so maybe 3. Hmm, but depending on context. If the product is supposed to be sturdy, weight might be an issue. Without more info, maybe 3 as neutral.\n",
      "\n",
      "Review 430: Coverage didn't match ads. Negative, so probably 1 or 0. Since it's a clear issue, 1.\n",
      "\n",
      "Review 431: \"Works fine,\" replacement, convenient. Neutral to slightly positive. Maybe 3.\n",
      "\n",
      "Review 432: Dried out upon arrival. Definitely negative, 0.\n",
      "\n",
      "Review 433: \"Perfect\" again, 4.\n",
      "\n",
      "Review 434: Issues with gems misplaced and stuck to cushion. Negative, 1.\n",
      "\n",
      "Review 435: Loves it, excellent quality, bright colors. Positive, 4.\n",
      "\n",
      "Review 436: Itchy fabric, wrinkles, uncomfortable. Negative, maybe 1.\n",
      "\n",
      "Review 437: Mixed. Likes product except misses applicator. Positive aspects outweigh the minus. Maybe 3.\n",
      "\n",
      "Review 438: Positive but short-term. \"So far so good.\" Maybe 3, cautious but positive.\n",
      "\n",
      "Review 439: Helps with jobs, positive experience. 4.\n",
      "\n",
      "Review 440: Just what needed. Positive, 4.\n",
      "\n",
      "Review 441: Excellent value. 4.\n",
      "\n",
      "Review 442: Collapsible is good but not universal. Slightly negative but some positive. Maybe 2.\n",
      "\n",
      "Review 443: Regret purchasing, strong negative. 0.\n",
      "\n",
      "Review 444: Smell good, helps hair. Positive, 3? Or 4 if strong positive. Maybe 4.\n",
      "\n",
      "Review 445: Great for hard areas. 4.\n",
      "\n",
      "Review 446: Poor return policy. Negative, 1.\n",
      "\n",
      "Review 447: Loves it for frizzy hair. 4.\n",
      "\n",
      "Review 448: As described, works well. 4.\n",
      "\n",
      "Review 449: Skin seems firmer. Positive, 4.\n",
      "\n",
      "Review 450: Good for a kid, but smaller quantity. Maybe 3.\n",
      "\n",
      "Review 451: Detailed positive review of a wand. Very positive. 4.\n",
      "\n",
      "Review 452: Criticizes product as bad, not recommended. 0.\n",
      "\n",
      "Review 453: Loves colors and comfort. 4.\n",
      "\n",
      "Review 454: Leaks, thrown away. 0.\n",
      "\n",
      "Review 455: Spanish for \"Super good,\" positive. 4.\n",
      "\n",
      "Review 456: Keeps feet/feet soft, good price. Positive, 4.\n",
      "\n",
      "Review 457: Holds toiletries well. Positive, 4.\n",
      "\n",
      "Review 458: Helps with tension. 3.\n",
      "\n",
      "Review 459: Returns product, not suitable for family. Mixed, maybe 2.\n",
      "\n",
      "Review 460: Expensive soap, not worth it. 0.\n",
      "\n",
      "Review 461: Wishes for original version, not impressed. 1.\n",
      "\n",
      "Review 462: Detailed positive about wash cloth. 4.\n",
      "\n",
      "Review 463: Broken when received but fixed. Neutral to positive. Maybe 3.\n",
      "\n",
      "Review 464: Not as effective as others, expensive. Negative. 0.\n",
      "\n",
      "Review 465: Easy to use. 3.\n",
      "\n",
      "Review 466: Mix of likes and dislikes (smell). 3.\n",
      "\n",
      "Review 467: Used but not as advertised. 1.\n",
      "\n",
      "Review 468: Works well, minor issues. 4.\n",
      "\n",
      "Review 469: Great product, durable. 4.\n",
      "\n",
      "Review 470: Worth it and cheaper. 4.\n",
      "\n",
      "Review 471: Dentist's approval, positive. 4.\n",
      "\n",
      "Review 472: Uses in routine, positive. 4.\n",
      "\n",
      "Review 473: Negative video review, 0.\n",
      "\n",
      "Review 474: Love soft hair. 4.\n",
      "\n",
      "Review 475: Didn't work as expected. 0.\n",
      "\n",
      "Review 476: Doesn't work for hair type. 0.\n",
      "\n",
      "Review 477: Disappointed in shape. 1.\n",
      "\n",
      "Review 478: Good for the purpose. 4.\n",
      "\n",
      "Review 479: Looking forward to using, no issues yet. 3.\n",
      "</think>\n",
      "\n",
      "[{\"index\":\"420\",\"sentiment_rating\":\"4\"},{\"index\":\"421\",\"sentiment_rating\":\"4\"},{\"index\":\"422\",\"sentiment_rating\":\"4\"},{\"index\":\"423\",\"sentiment_rating\":\"4\"},{\"index\":\"424\",\"sentiment_rating\":\"4\"},{\"index\":\"425\",\"sentiment_rating\":\"1\"},{\"index\":\"426\",\"sentiment_rating\":\"4\"},{\"index\":\"427\",\"sentiment_rating\":\"4\"},{\"index\":\"428\",\"sentiment_rating\":\"4\"},{\"index\":\"429\",\"sentiment_rating\":\"2\"},{\"index\":\"430\",\"sentiment_rating\":\"1\"},{\"index\":\"431\",\"sentiment_rating\":\"3\"},{\"index\":\"432\",\"sentiment_rating\":\"0\"},{\"index\":\"433\",\"sentiment_rating\":\"4\"},{\"index\":\"434\",\"sentiment_rating\":\"1\"},{\"index\":\"435\",\"sentiment_rating\":\"4\"},{\"index\":\"436\",\"sentiment_rating\":\"1\"},{\"index\":\"437\",\"sentiment_rating\":\"3\"},{\"index\":\"438\",\"sentiment_rating\":\"3\"},{\"index\":\"439\",\"sentiment_rating\":\"4\"},{\"index\":\"440\",\"sentiment_rating\":\"4\"},{\"index\":\"441\",\"sentiment_rating\":\"4\"},{\"index\":\"442\",\"sentiment_rating\":\"2\"},{\"index\":\"443\",\"sentiment_rating\":\"0\"},{\"index\":\"444\",\"sentiment_rating\":\"4\"},{\"index\":\"445\",\"sentiment_rating\":\"4\"},{\"index\":\"446\",\"sentiment_rating\":\"1\"},{\"index\":\"447\",\"sentiment_rating\":\"4\"},{\"index\":\"448\",\"sentiment_rating\":\"4\"},{\"index\":\"449\",\"sentiment_rating\":\"4\"},{\"index\":\"450\",\"sentiment_rating\":\"3\"},{\"index\":\"451\",\"sentiment_rating\":\"4\"},{\"index\":\"452\",\"sentiment_rating\":\"0\"},{\"index\":\"453\",\"sentiment_rating\":\"4\"},{\"index\":\"454\",\"sentiment_rating\":\"0\"},{\"index\":\"455\",\"sentiment_rating\":\"4\"},{\"index\":\"456\",\"sentiment_rating\":\"4\"},{\"index\":\"457\",\"sentiment_rating\":\"4\"},{\"index\":\"458\",\"sentiment_rating\":\"3\"},{\"index\":\"459\",\"sentiment_rating\":\"2\"},{\"index\":\"460\",\"sentiment_rating\":\"0\"},{\"index\":\"461\",\"sentiment_rating\":\"1\"},{\"index\":\"462\",\"sentiment_rating\":\"4\"},{\"index\":\"463\",\"sentiment_rating\":\"3\"},{\"index\":\"464\",\"sentiment_rating\":\"0\"},{\"index\":\"465\",\"sentiment_rating\":\"3\"},{\"index\":\"466\",\"sentiment_rating\":\"3\"},{\"index\":\"467\",\"sentiment_rating\":\"1\"},{\"index\":\"468\",\"sentiment_rating\":\"4\"},{\"index\":\"469\",\"sentiment_rating\":\"4\"},{\"index\":\"470\",\"sentiment_rating\":\"4\"},{\"index\":\"471\",\"sentiment_rating\":\"4\"},{\"index\":\"472\",\"sentiment_rating\":\"4\"},{\"index\":\"473\",\"sentiment_rating\":\"0\"},{\"index\":\"474\",\"sentiment_rating\":\"4\"},{\"index\":\"475\",\"sentiment_rating\":\"0\"},{\"index\":\"476\",\"sentiment_rating\":\"0\"},{\"index\":\"477\",\"sentiment_rating\":\"1\"},{\"index\":\"478\",\"sentiment_rating\":\"4\"},{\"index\":\"479\",\"sentiment_rating\":\"3\"}]\n",
      "Error parsing response: 'list' object has no attribute 'keys'\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "model = \"qwen/qwen3-32b\"\n",
    "chunk_size = 60\n",
    "\n",
    "all_predictions, all_responses = predict_sentiments_groq(sample_text=sample_text, \n",
    "                                         chunk_size=chunk_size, \n",
    "                                         model=model,\n",
    "                                         few_shot=True,\n",
    "                                         cot=True,\n",
    "                                         binary=False,\n",
    "                                         response_format=False) \n",
    "\n",
    "# Sometimes the response is not properly formatted, so we need to do some text cleaning\n",
    "all_pred = pd.DataFrame()\n",
    "for i in all_responses:\n",
    "    content = i.split('</think>')[-1].replace('```json', '').replace('```', '').strip()\n",
    "    json_content = json.loads(content)\n",
    "    try:\n",
    "        df = pd.DataFrame(json_content['reviews'])\n",
    "    except Exception as e:\n",
    "        df = pd.DataFrame(json_content)\n",
    "        # break\n",
    "    all_pred = pd.concat([all_pred, df], ignore_index=True)\n",
    "\n",
    "if 'sentiment_rate' in all_pred.columns:\n",
    "    all_pred['sentiment_rating'] = np.where(all_pred['sentiment_rating'].notna(),\n",
    "                                        all_pred['sentiment_rating'],\n",
    "                                            all_pred['sentiment_rate'])\n",
    "\n",
    "test_qwen['pred_qwen3_cot_5s'] = all_pred['sentiment_rating'].astype(int)\n",
    "test_qwen.to_csv(\"results/test_5_llm_qwen3_32b.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5485d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data512_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
