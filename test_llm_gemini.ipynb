{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a991394",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "import time\n",
    "import json\n",
    "from google import genai\n",
    "from google.genai import types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "050c9873",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "client = genai.Client()\n",
    "\n",
    "test = pd.read_parquet(\"data/test_10k_5.parquet\")\n",
    "sample_text = test.text.to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08418248",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptGenerator:\n",
    "    def __init__(self, few_shot, cot, binary=False):\n",
    "        self.few_shot = few_shot\n",
    "        self.cot = cot\n",
    "        self.binary = binary\n",
    "\n",
    "    def generate_general_instruction(self, batch_size):\n",
    "        if self.binary:\n",
    "            sentiment_scale = \"\"\"3.  **Sentiment Scale:** 0 = Negative and 1 =  Positive.\"\"\"\n",
    "        else:\n",
    "            sentiment_scale = \"\"\"3.  **Sentiment Scale:** Use a 5-point star rating (0 = Very Negative, 4 = Very Positive).\"\"\"\n",
    "        \n",
    "        general_instruction = f\"\"\"\n",
    "            Analyze the sentiment for the {batch_size} Amazon product reviews provided below.\n",
    "            The unique index for each review is provided in the '<review id=\"...\">' tag.\n",
    "\n",
    "            # --- INSTRUCTIONS & CONSTRAINTS ---\n",
    "            1.  **Strict Output:** Your final output MUST be a single, valid JSON object containing a 'reviews' array.\n",
    "            2.  **Indexing:** The 'index' field in your JSON output MUST correspond exactly to the 'id' extracted from the <review id=\"...\"> tag.\n",
    "            {sentiment_scale}\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        return general_instruction\n",
    "    \n",
    "    def generate_cot_instruction(self):\n",
    "        if self.binary:\n",
    "            scale = \"\"\"4. Assign the final sentiment rating (0 or 1).\"\"\"\n",
    "        else:\n",
    "            scale = \"\"\"4. Assign the final sentiment rating (0, 1, 2, 3, or 4).\"\"\"\n",
    "            \n",
    "        cot_instruction = f\"\"\"\n",
    "            # --- CHAIN OF THOUGHT (CoT) PROCESS ---\n",
    "            For each review, you MUST perform a Chain-of-Thought process and enclose it in a <CoT> XML tag. This process helps ensure accuracy. Your reasoning must follow these steps:\n",
    "            <CoT>\n",
    "            1. Identify the main sentiment/emotion (e.g., happiness, frustration, disappointment).\n",
    "            2. List specific positive aspects (+ve) and negative aspects (-ve) mentioned in the review.\n",
    "            3. Evaluate the overall net sentiment, giving appropriate weight to pros and cons.\n",
    "            {scale}\n",
    "            </CoT>\n",
    "            \n",
    "            You MUST include this <CoT> reasoning for each review in your response.\n",
    "            \"\"\"\n",
    "        \n",
    "        return cot_instruction\n",
    "\n",
    "    def generate_few_shot_examples(self):\n",
    "        if self.binary:\n",
    "            few_shot_examples = [\n",
    "                # --- Example 1 ---\n",
    "                types.Content(\n",
    "                    role=\"user\",\n",
    "                    parts=[types.Part.from_text(text=\"\"\"<review id=\\\\'1\\\\'>So glad I could get my deodorant online at Amazon. This has a great scent too.</review>\"\"\")],\n",
    "                ),\n",
    "                types.Content(\n",
    "                    role=\"model\",\n",
    "                    parts=[types.Part.from_text(text=\"\"\"{{\"index\": '1', \"sentiment_rating\": \"1\"}}\"\"\")],\n",
    "                ),\n",
    "                # --- Example 2 ---\n",
    "                types.Content(\n",
    "                    role=\"user\",\n",
    "                    parts=[types.Part.from_text(text=\"\"\"<review id=\\\\'5\\\\'>It is not organic , it's made in china, left my hair dry ... returning .</review>\"\"\")],\n",
    "                ),\n",
    "                types.Content(\n",
    "                    role=\"model\",\n",
    "                    parts=[types.Part.from_text(text=\"\"\"{{\"index\": '5', \"sentiment_rating\": \"0\"}}\"\"\")],\n",
    "                ),\n",
    "                # --- End of Few-Shot Examples ---\n",
    "            ]\n",
    "        else:\n",
    "            few_shot_examples = [\n",
    "                # --- Example 1 ---\n",
    "                types.Content(\n",
    "                    role=\"user\",\n",
    "                    parts=[types.Part.from_text(text=\"\"\"<review id=\\\\'1\\\\'>So glad I could get my deodorant online at Amazon. This has a great scent too.</review>\"\"\")],\n",
    "                ),\n",
    "                types.Content(\n",
    "                    role=\"model\",\n",
    "                    parts=[types.Part.from_text(text=\"\"\"{{\"index\": '1', \"sentiment_rating\": \"4\"}}\"\"\")],\n",
    "                ),\n",
    "                # --- Example 2 ---\n",
    "                types.Content(\n",
    "                    role=\"user\",\n",
    "                    parts=[types.Part.from_text(text=\"\"\"<review id=\\\\'2\\\\'>extremely metallic, two coats does the trick. however, the chemical smell is EXTREMELY strong. you need to open a window and run a fan while applying.</review>\"\"\")],\n",
    "                ),\n",
    "                types.Content(\n",
    "                    role=\"model\",\n",
    "                    parts=[types.Part.from_text(text=\"\"\"{{\"index\": '2', \"sentiment_rating\": \"3\"}}\"\"\")],\n",
    "                ),\n",
    "                # --- Example 3 ---\n",
    "                types.Content(\n",
    "                    role=\"user\",\n",
    "                    parts=[types.Part.from_text(text=\"\"\"<review id=\\\\'3\\\\'>Very, very thin,, not to absorbent</review>\"\"\")],\n",
    "                ),\n",
    "                types.Content(\n",
    "                    role=\"model\",\n",
    "                    parts=[types.Part.from_text(text=\"\"\"{{\"index\": '3', \"sentiment_rating\": \"2\"}}\"\"\")],\n",
    "                ),\n",
    "                # --- Example 4 ---\n",
    "                types.Content(\n",
    "                    role=\"user\",\n",
    "                    parts=[types.Part.from_text(text=\"\"\"<review id=\\\\'4\\\\'>Relatively short and not good for kinky hair.</review>\"\"\")],\n",
    "                ),\n",
    "                types.Content(\n",
    "                    role=\"model\",\n",
    "                    parts=[types.Part.from_text(text=\"\"\"{{\"index\": '4', \"sentiment_rating\": \"1\"}}\"\"\")],\n",
    "                ),\n",
    "                # --- Example 5 ---\n",
    "                types.Content(\n",
    "                    role=\"user\",\n",
    "                    parts=[types.Part.from_text(text=\"\"\"<review id=\\\\'5\\\\'>It is not organic , it's made in china, left my hair dry ... returning .</review>\"\"\")],\n",
    "                ),\n",
    "                types.Content(\n",
    "                    role=\"model\",\n",
    "                    parts=[types.Part.from_text(text=\"\"\"{{\"index\": '5', \"sentiment_rating\": \"0\"}}\"\"\")],\n",
    "                ),\n",
    "                # --- End of Few-Shot Examples ---\n",
    "            ]\n",
    "        return few_shot_examples\n",
    "\n",
    "\n",
    "    def generate_final_instruction(self, batch, text_batch):\n",
    "        final_instruction = f\"\"\"\n",
    "                --- REVIEWS START ---\n",
    "                {text_batch}\n",
    "                --- REVIEWS END ---\n",
    "            \"\"\"\n",
    "        return final_instruction\n",
    "\n",
    "    def gen_guery(self, batch_size, text_batch):\n",
    "        general_instruction = self.generate_general_instruction(batch_size)\n",
    "        \n",
    "        cot_instruction = ''\n",
    "        if self.cot:\n",
    "            cot_instruction = self.generate_cot_instruction()\n",
    "        \n",
    "        final_instruction = self.generate_final_instruction(batch_size, text_batch)\n",
    "\n",
    "        if self.few_shot:\n",
    "            instructions_query = [\n",
    "                types.Content(\n",
    "                    role=\"user\",\n",
    "                    parts=[types.Part.from_text(text=general_instruction + cot_instruction )],\n",
    "                )\n",
    "            ]\n",
    "            few_shot_examples = self.generate_few_shot_examples()\n",
    "            review_query = [\n",
    "                types.Content(\n",
    "                    role=\"user\",\n",
    "                    parts=[types.Part.from_text(text=final_instruction)],\n",
    "                )\n",
    "            ]\n",
    "            return instructions_query + few_shot_examples + review_query\n",
    "        else:\n",
    "            return [\n",
    "                types.Content(\n",
    "                    role=\"user\",\n",
    "                    parts=[types.Part.from_text(text=general_instruction + cot_instruction + final_instruction)],\n",
    "                )\n",
    "            ]\n",
    "    def generate_output_schema(self, batch_size):\n",
    "\n",
    "        if self.binary:\n",
    "            sentiment_enum = [\"0\", \"1\"]\n",
    "            description = \"The sentiment score, either 0 (negative) or 1 (positive).\"\n",
    "        else:\n",
    "            sentiment_enum = [\"0\", \"1\", \"2\", \"3\", \"4\"]\n",
    "            description = \"The sentiment score, from 0 (very negative) to 4 (very positive).\"\n",
    "        # 1. Define the schema for a single review's output\n",
    "        REVIEW_SCHEMA = types.Schema(\n",
    "            type=types.Type.OBJECT,\n",
    "            properties={\n",
    "                \"index\": types.Schema(\n",
    "                    type=types.Type.INTEGER,\n",
    "                    description=\"The original 0-based index of the review in the input list.\"\n",
    "                ),\n",
    "                \"sentiment_rating\": types.Schema(\n",
    "                    type=types.Type.STRING,\n",
    "                    description=description,\n",
    "                    # THE FIX IS HERE: Change the enum values to strings\n",
    "                    enum=sentiment_enum\n",
    "                ),\n",
    "            },\n",
    "            required=[\"index\", \"sentiment_rating\"]\n",
    "        )\n",
    "\n",
    "        # 2. Define the final output schema as an array of these review objects\n",
    "        OUTPUT_SCHEMA = types.Schema(\n",
    "            type=types.Type.OBJECT,\n",
    "            properties={\n",
    "                \"reviews\": types.Schema(\n",
    "                    type=types.Type.ARRAY,\n",
    "                    items=REVIEW_SCHEMA,\n",
    "                    description=f\"A list of {batch_size} sentiment ratings, one for each input review.\"\n",
    "                )\n",
    "            },\n",
    "            required=[\"reviews\"]\n",
    "        )\n",
    "        return OUTPUT_SCHEMA\n",
    "    \n",
    "    def generate_system_instruction(self):\n",
    "        if self.binary:\n",
    "            content = \"3.  **Content:** For each review, provide the sentiment as a string representation of an integer: either 0 (negative) or 1 (positive).\"\n",
    "        else:\n",
    "            content = \"3.  **Content:** For each review, provide the sentiment as a string representation of an integer from 0 (very negative) to 4 (very positive).\"\n",
    "        system_instruction = f\"\"\"\n",
    "            You are an expert sentiment analyst for Amazon product reviews. Your task is to process a batch of reviews and output the results as a single JSON object.\n",
    "\n",
    "            1.  **Strict Output Format:** You MUST adhere strictly to the provided JSON schema. Your entire response must be a valid JSON object.\n",
    "            2.  **Indexing:** The 'reviews' array MUST contain the same number of items as the input reviews, and each item's 'index' MUST correspond exactly to the review's sequential position.\n",
    "            {content}\n",
    "            4.  **No Explanation:** DO NOT include any introductory text, explanation, or any Markdown fences (like ```json or ```) outside of the required JSON object.\n",
    "            \"\"\"\n",
    "        return system_instruction\n",
    "\n",
    "\n",
    "def predict_sentiments(sample_text, chunk_size, model, few_shot, cot, binary):\n",
    "    client = genai.Client()\n",
    "    all_predictions = []\n",
    "    for i in range(0, len(sample_text), chunk_size):\n",
    "        # Get a slice of the reviews\n",
    "        batch = sample_text[i:i + chunk_size]\n",
    "        text_batch = ''\n",
    "        for ind, text in enumerate(batch):\n",
    "            # Use a clear XML tag for each review and its index\n",
    "            text_batch += f\"<review id='{i + ind}'>{text}</review>\\n\"\n",
    "        # try to generate content if error occurs wait and retry\n",
    "\n",
    "        prompt_generator = PromptGenerator(few_shot=few_shot, cot=cot, binary=binary)\n",
    "        query = prompt_generator.gen_guery(batch_size=len(batch), text_batch=text_batch)\n",
    "        system_instruction = prompt_generator.generate_system_instruction()\n",
    "        output_schema = prompt_generator.generate_output_schema(batch_size=len(batch))\n",
    "\n",
    "        try_count = 0\n",
    "        while try_count < 10:\n",
    "            try:\n",
    "                try_count += 1\n",
    "                response = client.models.generate_content(\n",
    "                    model=model,\n",
    "                    contents=query,\n",
    "                    config=types.GenerateContentConfig(\n",
    "                        system_instruction=system_instruction,\n",
    "                        response_mime_type=\"application/json\", # <--- CRITICAL: Request JSON output\n",
    "                        response_schema=output_schema          # <--- CRITICAL: Pass the defined schema\n",
    "                    )\n",
    "                )\n",
    "                break  # Exit the retry loop if successful\n",
    "            except Exception as e:\n",
    "                print(f\"Error occurred: {e}. Retrying in 60 seconds...\")\n",
    "                time.sleep(60)   \n",
    "\n",
    "        response_data = json.loads(response.text)\n",
    "        response_data = response_data['reviews']\n",
    "        print(len(response_data))\n",
    "        \n",
    "        all_predictions.extend(response_data)\n",
    "        time.sleep(60)  # To avoid rate limiting\n",
    "\n",
    "    return all_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f395d32",
   "metadata": {},
   "source": [
    "# Gemini 2.5 PRO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e422cae",
   "metadata": {},
   "source": [
    "## Zero-Shot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94e292bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "model = \"gemini-2.5-pro\"\n",
    "chunk_size = 200\n",
    "all_predictions = predict_sentiments(sample_text, chunk_size, model, few_shot=False, cot=False, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "153ae431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.683)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['pred_0s'] = pd.DataFrame(all_predictions)['sentiment_rating'].astype(int)\n",
    "(test['pred_0s'] == test['rating']).sum()/len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b57eb1",
   "metadata": {},
   "source": [
    "## Few-shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c32db3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "model = \"gemini-2.5-pro\"\n",
    "chunk_size = 200\n",
    "all_predictions = predict_sentiments(sample_text, chunk_size, model, few_shot=True, cot=False, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c73ca2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.724)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['pred_5s'] = pd.DataFrame(all_predictions)['sentiment_rating'].astype(int)\n",
    "(test['pred_5s'] == test['rating']).sum()/len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78cce79",
   "metadata": {},
   "source": [
    "## Chain-of-thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "185da9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "model = \"gemini-2.5-pro\"\n",
    "chunk_size = 200\n",
    "all_predictions = predict_sentiments(sample_text, chunk_size, model, few_shot=False, cot=True, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95d44698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.684)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['pred_cot'] = pd.DataFrame(all_predictions)['sentiment_rating'].astype(int)\n",
    "(test['pred_cot'] == test['rating']).sum()/len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78e7b81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "model = \"gemini-2.5-pro\"\n",
    "chunk_size = 200\n",
    "all_predictions = predict_sentiments(sample_text, chunk_size, model, few_shot=True, cot=True, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d5f8b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.731)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['pred_cot_5s'] = pd.DataFrame(all_predictions)['sentiment_rating'].astype(int)\n",
    "(test['pred_cot_5s'] == test['rating']).sum()/len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3828687a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv(\"results/test_10k_5_with_gemini_25_pro_preds.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ad18d6",
   "metadata": {},
   "source": [
    "# Binary Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a777f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_parquet(\"data/test_10k_2.parquet\")\n",
    "sample_text = test.text.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fd04a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "model = \"gemini-2.5-pro\"\n",
    "chunk_size = 200\n",
    "all_predictions = predict_sentiments(sample_text, chunk_size, model, few_shot=False, cot=False, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01be367c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.985)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['pred_0s'] = pd.DataFrame(all_predictions)['sentiment_rating'].astype(int)\n",
    "(test['pred_0s'] == test['rating']).sum()/len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b44fc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('results/test_10k_2_with_gemini_25_pro_preds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72c70d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "model = \"gemini-2.5-pro\"\n",
    "chunk_size = 200\n",
    "all_predictions = predict_sentiments(sample_text, chunk_size, model, few_shot=True, cot=False, binary=True)\n",
    "test['pred_2s'] = pd.DataFrame(all_predictions)['sentiment_rating'].astype(int)\n",
    "(test['pred_2s'] == test['rating']).sum()/len(test)\n",
    "test.to_csv('results/test_10k_2_with_gemini_25_pro_preds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a19d9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "0.984\n"
     ]
    }
   ],
   "source": [
    "model = \"gemini-2.5-pro\"\n",
    "chunk_size = 200\n",
    "all_predictions = predict_sentiments(sample_text, chunk_size, model, few_shot=False, cot=True, binary=True)\n",
    "test['pred_cot'] = pd.DataFrame(all_predictions)['sentiment_rating'].astype(int)\n",
    "print((test['pred_cot'] == test['rating']).sum()/len(test))\n",
    "test.to_csv('results/test_10k_2_with_gemini_25_pro_preds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c54fca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.985)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = \"gemini-2.5-pro\"\n",
    "chunk_size = 200\n",
    "all_predictions = predict_sentiments(sample_text, chunk_size, model, few_shot=True, cot=True, binary=True)\n",
    "test['pred_cot_2s'] = pd.DataFrame(all_predictions)['sentiment_rating'].astype(int)\n",
    "(test['pred_cot_2s'] == test['rating']).sum()/len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ef355c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv(\"results/test_10k_2_with_gemini_25_pro_preds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae868b79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data512_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
