{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a991394",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "import time\n",
    "import json\n",
    "\n",
    "\n",
    "from groq import Groq\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "test = pd.read_parquet(\"data/test_10k_5.parquet\")\n",
    "sample_text = test.text.to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8594061d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptGenerator:\n",
    "    def __init__(self, few_shot, cot, binary=False):\n",
    "        self.few_shot = few_shot\n",
    "        self.cot = cot\n",
    "        self.binary = binary\n",
    "\n",
    "    def generate_general_instruction(self, batch_size):\n",
    "        if self.binary:\n",
    "            sentiment_scale = \"\"\"3.  **Sentiment Scale:** 0 = Negative and 1 =  Positive.\"\"\"\n",
    "        else:\n",
    "            sentiment_scale = \"\"\"3.  **Sentiment Scale:** Use a 5-point star rating (0 = Very Negative, 4 = Very Positive).\"\"\"\n",
    "        \n",
    "        general_instruction = f\"\"\"\n",
    "            Analyze the sentiment for the {batch_size} Amazon product reviews provided below.\n",
    "            The unique index for each review is provided in the '<review id=\"...\">' tag.\n",
    "\n",
    "            # --- INSTRUCTIONS & CONSTRAINTS ---\n",
    "            1.  **Strict Output:** Your final output MUST be a single, valid JSON object containing a 'reviews' array.\n",
    "            2.  **Indexing:** The 'index' field in your JSON output MUST correspond exactly to the 'id' extracted from the <review id=\"...\"> tag.\n",
    "            {sentiment_scale}\n",
    "            4.  **No Explanation:** Do NOT include any introductory text, explanation, your thought process, or any Markdown fences (like ```json or ```) outside of the required JSON object.\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        return general_instruction\n",
    "    \n",
    "    def generate_cot_instruction(self):\n",
    "        if self.binary:\n",
    "            scale = \"\"\"4. Assign the final sentiment rating (0 or 1).\"\"\"\n",
    "        else:\n",
    "            scale = \"\"\"4. Assign the final sentiment rating (0, 1, 2, 3, or 4).\"\"\"\n",
    "            \n",
    "        cot_instruction = f\"\"\"\n",
    "            # --- CHAIN OF THOUGHT (CoT) PROCESS ---\n",
    "            For each review, you MUST perform a Chain-of-Thought process and enclose it in a <CoT> XML tag. This process helps ensure accuracy. Your reasoning must follow these steps:\n",
    "            <CoT>\n",
    "            1. Identify the main sentiment/emotion (e.g., happiness, frustration, disappointment).\n",
    "            2. List specific positive aspects (+ve) and negative aspects (-ve) mentioned in the review.\n",
    "            3. Evaluate the overall net sentiment, giving appropriate weight to pros and cons.\n",
    "            {scale}\n",
    "            </CoT>\n",
    "            \n",
    "            You MUST include this <CoT> reasoning for each review in your response.\n",
    "            \"\"\"\n",
    "        \n",
    "        return cot_instruction\n",
    "\n",
    "    def generate_few_shot_examples(self):\n",
    "        if self.binary:\n",
    "            few_shot_examples = [\n",
    "                # --- Example 1 ---\n",
    "                {\n",
    "                    \"role\":\"user\",\n",
    "                    \"content\":\"\"\"<review id=\\\\'1\\\\'>So glad I could get my deodorant online at Amazon. This has a great scent too.</review>\"\"\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\":\"assistant\",\n",
    "                    \"content\":\"\"\"{{\"index\": '1', \"sentiment_rating\": \"1\"}}\"\"\",\n",
    "                },\n",
    "                # --- Example 2 ---\n",
    "                {\n",
    "                    \"role\":\"user\",\n",
    "                    \"content\":\"\"\"<review id=\\\\'5\\\\'>It is not organic , it's made in china, left my hair dry ... returning .</review>\"\"\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\":\"assistant\",\n",
    "                    \"content\":\"\"\"{{\"index\": '5', \"sentiment_rating\": \"0\"}}\"\"\",\n",
    "                },\n",
    "                # --- End of Few-Shot Examples ---\n",
    "            ]\n",
    "        else:\n",
    "            few_shot_examples = [\n",
    "                # --- Example 1 ---\n",
    "                {\n",
    "                    \"role\":\"user\",\n",
    "                    \"content\":\"\"\"<review id=\\\\'1\\\\'>So glad I could get my deodorant online at Amazon. This has a great scent too.</review>\"\"\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\":\"assistant\",\n",
    "                    \"content\":\"\"\"{{\"index\": '1', \"sentiment_rating\": \"4\"}}\"\"\",\n",
    "                },\n",
    "                # --- Example 2 ---\n",
    "                {\n",
    "                    \"role\":\"user\",\n",
    "                    \"content\":\"\"\"<review id=\\\\'2\\\\'>extremely metallic, two coats does the trick. however, the chemical smell is EXTREMELY strong. you need to open a window and run a fan while applying.</review>\"\"\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\":\"assistant\",\n",
    "                    \"content\":\"\"\"{{\"index\": '2', \"sentiment_rating\": \"3\"}}\"\"\",\n",
    "                },\n",
    "                # --- Example 3 ---\n",
    "                {\n",
    "                    \"role\":\"user\",\n",
    "                    \"content\":\"\"\"<review id=\\\\'3\\\\'>Very, very thin,, not to absorbent</review>\"\"\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\":\"assistant\",\n",
    "                    \"content\":\"\"\"{{\"index\": '3', \"sentiment_rating\": \"2\"}}\"\"\",\n",
    "                },\n",
    "                # --- Example 4 ---\n",
    "                {\n",
    "                    \"role\":\"user\",\n",
    "                    \"content\":\"\"\"<review id=\\\\'4\\\\'>Relatively short and not good for kinky hair.</review>\"\"\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\":\"assistant\",\n",
    "                    \"content\":\"\"\"{{\"index\": '4', \"sentiment_rating\": \"1\"}}\"\"\",\n",
    "                },\n",
    "                # --- Example 5 ---\n",
    "                {\n",
    "                    \"role\":\"user\",\n",
    "                    \"content\":\"\"\"<review id=\\\\'5\\\\'>It is not organic , it's made in china, left my hair dry ... returning .</review>\"\"\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\":\"assistant\",\n",
    "                    \"content\":\"\"\"{{\"index\": '5', \"sentiment_rating\": \"0\"}}\"\"\",\n",
    "                },\n",
    "                # --- End of Few-Shot Examples ---\n",
    "            ]\n",
    "        return few_shot_examples\n",
    "\n",
    "\n",
    "    def generate_final_instruction(self, batch, text_batch):\n",
    "        final_instruction = f\"\"\"\n",
    "                --- REVIEWS START ---\n",
    "                {text_batch}\n",
    "                --- REVIEWS END ---\n",
    "            \"\"\"\n",
    "        return final_instruction\n",
    "\n",
    "    def gen_guery(self, batch_size, text_batch):\n",
    "        general_instruction = self.generate_general_instruction(batch_size)\n",
    "        \n",
    "        cot_instruction = ''\n",
    "        if self.cot:\n",
    "            cot_instruction = self.generate_cot_instruction()\n",
    "        \n",
    "        final_instruction = self.generate_final_instruction(batch_size, text_batch)\n",
    "\n",
    "        if self.few_shot:\n",
    "            instructions_query = [\n",
    "                {\n",
    "                    \"role\":\"user\",\n",
    "                    \"content\":general_instruction + cot_instruction,\n",
    "                }\n",
    "            ]\n",
    "            few_shot_examples = self.generate_few_shot_examples()\n",
    "            review_query = [\n",
    "                {\n",
    "                    \"role\":\"user\",\n",
    "                    \"content\":final_instruction,\n",
    "                }\n",
    "            ]\n",
    "            return instructions_query + few_shot_examples + review_query\n",
    "        else:\n",
    "            return [\n",
    "                {\n",
    "                    \"role\":\"user\",\n",
    "                    \"content\":general_instruction + cot_instruction + final_instruction,\n",
    "                }\n",
    "            ]\n",
    "        \n",
    "    def generate_output_schema(self):\n",
    "        if self.binary:\n",
    "            sentiment_enum = [\"0\", \"1\"]\n",
    "        else:\n",
    "            sentiment_enum = [\"0\", \"1\", \"2\", \"3\", \"4\"]\n",
    "\n",
    "        response_format = {\n",
    "            'type': \"json_schema\",\n",
    "            'json_schema': {\n",
    "                'name': \"product_review\",\n",
    "                'schema': {\n",
    "                    'type': \"object\",\n",
    "                    'properties': {\n",
    "                    'index': { 'type': \"string\" },\n",
    "                    'sentiment_rating': { \n",
    "                        'type': \"string\",\n",
    "                        'enum': sentiment_enum\n",
    "                        },\n",
    "                    },\n",
    "                'required': [\"index\", \"sentiment_rating\"],\n",
    "                'additionalProperties': False\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        return response_format\n",
    "    \n",
    "    def generate_system_query(self):\n",
    "        if self.binary:\n",
    "            content = \"2.  **Content:** For each review, provide the sentiment as a string representation of an integer: either 0 (negative) or 1 (positive).\"\n",
    "        else:\n",
    "            content = \"2.  **Content:** For each review, provide the sentiment as a string representation of an integer from 0 (very negative) to 4 (very positive).\"\n",
    "        system_instruction = f\"\"\"\n",
    "            You are an expert sentiment analyst for Amazon product reviews. Your task is to process a batch of reviews and output the results as a single JSON object.\n",
    "            1.  **Indexing:** The 'reviews' array MUST contain the same number of items as the input reviews, and each item's 'index' MUST correspond exactly to the review's sequential position.\n",
    "            {content}\n",
    "            3.  **No Explanation:** DO NOT include any introductory text, explanation, or any Markdown fences (like ```json or ```) outside of the required JSON object.\n",
    "            \"\"\"\n",
    "        \n",
    "        system_query = [{\"role\": \"system\", \"content\": system_instruction}]\n",
    "        return system_query\n",
    "\n",
    "def predict_sentiments_groq(sample_text, chunk_size, model, few_shot=False, cot=False, binary=False, response_format=True):\n",
    "    client_groq = Groq()\n",
    "    all_predictions = []\n",
    "    responses = []\n",
    "    for i in range(0, len(sample_text), chunk_size):\n",
    "        # Get a slice of the reviews\n",
    "        batch = sample_text[i:i + chunk_size]\n",
    "        text_batch = ''\n",
    "        for ind, text in enumerate(batch):\n",
    "            # Use a clear XML tag for each review and its index\n",
    "            text_batch += f\"<review id='{i + ind}'>{text}</review>\\n\"\n",
    "        # try to generate content if error occurs wait and retry\n",
    "        prompt_generator = PromptGenerator(few_shot=few_shot, cot=cot, binary=binary)\n",
    "        query = prompt_generator.gen_guery(batch_size=len(batch), text_batch=text_batch)\n",
    "        system_query = prompt_generator.generate_system_query()\n",
    "        if response_format:\n",
    "            response_format = prompt_generator.generate_output_schema()\n",
    "        messeages=system_query + query\n",
    "        try_count = 0\n",
    "        while try_count < 10:\n",
    "            try:\n",
    "                try_count += 1\n",
    "                if response_format:\n",
    "                    chat_completion = client_groq.chat.completions.create(\n",
    "                        messages=messeages,\n",
    "                        response_format=response_format,\n",
    "                        model=model,\n",
    "                    )\n",
    "                else:\n",
    "                    chat_completion = client_groq.chat.completions.create(\n",
    "                        messages=messeages,\n",
    "                        model=model,\n",
    "                    )\n",
    "                break  # Exit the retry loop if successful\n",
    "            except Exception as e:\n",
    "                print(f\"Error occurred: {e}. Retrying in 60 seconds...\")\n",
    "                time.sleep(60)   \n",
    "\n",
    "        # print(chat_completion.choices[0].message.content)\n",
    "        content = chat_completion.choices[0].message.content\n",
    "        responses.append(content)\n",
    "        \n",
    "        try:\n",
    "            if response_format:\n",
    "                response_data = json.loads(content)\n",
    "            else:\n",
    "                response_data = json.loads(content.split('</think>')[-1].replace('```json', '').replace('```', '').strip())\n",
    "            # response_data = json.loads(c)\n",
    "            # response_data = response_data['reviews']\n",
    "            key = list(response_data.keys())[0]\n",
    "            response_data = response_data[key]\n",
    "            print(len(response_data))\n",
    "            \n",
    "            all_predictions.extend(response_data)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(chat_completion.choices[0].message.content)\n",
    "            print(f\"Error parsing response: {e}\")\n",
    "            continue\n",
    "        \n",
    "        time.sleep(60)  # To avoid rate limiting\n",
    "\n",
    "    return all_predictions, responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f73ec4e",
   "metadata": {},
   "source": [
    "## llama-4-maverick-17b-128e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5a234ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_llama = pd.read_csv(\"results/test_10k_5_with_llm_llama_4_128e_preds.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "297412c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "\n",
    "client_groq = Groq()\n",
    "model = \"meta-llama/llama-4-maverick-17b-128e-instruct\"\n",
    "chunk_size = 50\n",
    "\n",
    "all_predictions, all_responses = predict_sentiments_groq(sample_text=sample_text, \n",
    "                                         chunk_size=chunk_size, \n",
    "                                         model=model,\n",
    "                                         few_shot=False,\n",
    "                                         cot=False,\n",
    "                                         binary=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d082f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.755)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_llama['pred_0s'] = pd.DataFrame(all_predictions)['sentiment_rating'].astype(int)\n",
    "(test_llama['pred_0s'] == test_llama['rating']).sum()/len(test_llama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a5952b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.746)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = \"meta-llama/llama-4-maverick-17b-128e-instruct\"\n",
    "chunk_size = 60\n",
    "all_predictions, all_responses = predict_sentiments_groq(sample_text=sample_text, \n",
    "                                          chunk_size=chunk_size, \n",
    "                                          model=model, \n",
    "                                          few_shot=True, \n",
    "                                          cot=False, \n",
    "                                          binary=False)\n",
    "\n",
    "test['pred_5s'] = pd.DataFrame(all_predictions)['sentiment_rating'].astype(int)\n",
    "(test['pred_5s'] == test['rating']).sum()/len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be532ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.739)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = \"meta-llama/llama-4-maverick-17b-128e-instruct\"\n",
    "chunk_size = 60\n",
    "all_predictions, all_responses = predict_sentiments_groq(sample_text=sample_text, \n",
    "                                          chunk_size=chunk_size, \n",
    "                                          model=model, \n",
    "                                          few_shot=False, \n",
    "                                          cot=True, \n",
    "                                          binary=False)\n",
    "\n",
    "test['pred_cot'] = pd.DataFrame(all_predictions)['sentiment_rating'].astype(int)\n",
    "(test['pred_cot'] == test['rating']).sum()/len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "83e1964e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "Error occurred: Error code: 429 - {'error': {'message': 'Rate limit reached for model `meta-llama/llama-4-maverick-17b-128e-instruct` in organization `org_01kahypfxmfw0sea725ejt1d2j` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 498956, Requested 3366. Please try again in 6m41.241599999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}. Retrying in 60 seconds...\n",
      "Error occurred: Error code: 429 - {'error': {'message': 'Rate limit reached for model `meta-llama/llama-4-maverick-17b-128e-instruct` in organization `org_01kahypfxmfw0sea725ejt1d2j` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 498608, Requested 3366. Please try again in 5m41.1072s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}. Retrying in 60 seconds...\n",
      "Error occurred: Error code: 429 - {'error': {'message': 'Rate limit reached for model `meta-llama/llama-4-maverick-17b-128e-instruct` in organization `org_01kahypfxmfw0sea725ejt1d2j` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 498260, Requested 3366. Please try again in 4m40.9728s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}. Retrying in 60 seconds...\n",
      "Error occurred: Error code: 429 - {'error': {'message': 'Rate limit reached for model `meta-llama/llama-4-maverick-17b-128e-instruct` in organization `org_01kahypfxmfw0sea725ejt1d2j` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 497913, Requested 3366. Please try again in 3m41.0112s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}. Retrying in 60 seconds...\n",
      "Error occurred: Error code: 429 - {'error': {'message': 'Rate limit reached for model `meta-llama/llama-4-maverick-17b-128e-instruct` in organization `org_01kahypfxmfw0sea725ejt1d2j` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 497565, Requested 3366. Please try again in 2m40.8768s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}. Retrying in 60 seconds...\n",
      "Error occurred: Error code: 429 - {'error': {'message': 'Rate limit reached for model `meta-llama/llama-4-maverick-17b-128e-instruct` in organization `org_01kahypfxmfw0sea725ejt1d2j` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 497217, Requested 3366. Please try again in 1m40.742399999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}. Retrying in 60 seconds...\n",
      "60\n",
      "Error occurred: Error code: 429 - {'error': {'message': 'Rate limit reached for model `meta-llama/llama-4-maverick-17b-128e-instruct` in organization `org_01kahypfxmfw0sea725ejt1d2j` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499652, Requested 3554. Please try again in 9m13.9968s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}. Retrying in 60 seconds...\n",
      "Error occurred: Error code: 429 - {'error': {'message': 'Rate limit reached for model `meta-llama/llama-4-maverick-17b-128e-instruct` in organization `org_01kahypfxmfw0sea725ejt1d2j` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499305, Requested 3554. Please try again in 8m14.0352s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}. Retrying in 60 seconds...\n",
      "Error occurred: Error code: 429 - {'error': {'message': 'Rate limit reached for model `meta-llama/llama-4-maverick-17b-128e-instruct` in organization `org_01kahypfxmfw0sea725ejt1d2j` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 498957, Requested 3554. Please try again in 7m13.9008s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}. Retrying in 60 seconds...\n",
      "Error occurred: Error code: 429 - {'error': {'message': 'Rate limit reached for model `meta-llama/llama-4-maverick-17b-128e-instruct` in organization `org_01kahypfxmfw0sea725ejt1d2j` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 498609, Requested 3554. Please try again in 6m13.7664s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}. Retrying in 60 seconds...\n",
      "Error occurred: Error code: 429 - {'error': {'message': 'Rate limit reached for model `meta-llama/llama-4-maverick-17b-128e-instruct` in organization `org_01kahypfxmfw0sea725ejt1d2j` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 498261, Requested 3554. Please try again in 5m13.632s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}. Retrying in 60 seconds...\n",
      "Error occurred: Error code: 429 - {'error': {'message': 'Rate limit reached for model `meta-llama/llama-4-maverick-17b-128e-instruct` in organization `org_01kahypfxmfw0sea725ejt1d2j` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 497913, Requested 3554. Please try again in 4m13.4976s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}. Retrying in 60 seconds...\n",
      "Error occurred: Error code: 429 - {'error': {'message': 'Rate limit reached for model `meta-llama/llama-4-maverick-17b-128e-instruct` in organization `org_01kahypfxmfw0sea725ejt1d2j` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 497565, Requested 3554. Please try again in 3m13.3632s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}. Retrying in 60 seconds...\n",
      "Error occurred: Error code: 429 - {'error': {'message': 'Rate limit reached for model `meta-llama/llama-4-maverick-17b-128e-instruct` in organization `org_01kahypfxmfw0sea725ejt1d2j` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 497217, Requested 3554. Please try again in 2m13.2288s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}. Retrying in 60 seconds...\n",
      "Error occurred: Error code: 429 - {'error': {'message': 'Rate limit reached for model `meta-llama/llama-4-maverick-17b-128e-instruct` in organization `org_01kahypfxmfw0sea725ejt1d2j` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 496870, Requested 3554. Please try again in 1m13.2672s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}. Retrying in 60 seconds...\n",
      "60\n",
      "Error occurred: Error code: 429 - {'error': {'message': 'Rate limit reached for model `meta-llama/llama-4-maverick-17b-128e-instruct` in organization `org_01kahypfxmfw0sea725ejt1d2j` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499652, Requested 3637. Please try again in 9m28.3392s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}. Retrying in 60 seconds...\n",
      "Error occurred: Error code: 429 - {'error': {'message': 'Rate limit reached for model `meta-llama/llama-4-maverick-17b-128e-instruct` in organization `org_01kahypfxmfw0sea725ejt1d2j` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499304, Requested 3637. Please try again in 8m28.2048s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}. Retrying in 60 seconds...\n",
      "Error occurred: Error code: 429 - {'error': {'message': 'Rate limit reached for model `meta-llama/llama-4-maverick-17b-128e-instruct` in organization `org_01kahypfxmfw0sea725ejt1d2j` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 498956, Requested 3637. Please try again in 7m28.070399999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}. Retrying in 60 seconds...\n",
      "Error occurred: Error code: 429 - {'error': {'message': 'Rate limit reached for model `meta-llama/llama-4-maverick-17b-128e-instruct` in organization `org_01kahypfxmfw0sea725ejt1d2j` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 498609, Requested 3637. Please try again in 6m28.1088s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}. Retrying in 60 seconds...\n",
      "Error occurred: Error code: 429 - {'error': {'message': 'Rate limit reached for model `meta-llama/llama-4-maverick-17b-128e-instruct` in organization `org_01kahypfxmfw0sea725ejt1d2j` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 498261, Requested 3637. Please try again in 5m27.9744s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}. Retrying in 60 seconds...\n",
      "Error occurred: Error code: 429 - {'error': {'message': 'Rate limit reached for model `meta-llama/llama-4-maverick-17b-128e-instruct` in organization `org_01kahypfxmfw0sea725ejt1d2j` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 497912, Requested 3637. Please try again in 4m27.667199999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}. Retrying in 60 seconds...\n",
      "Error occurred: Error code: 429 - {'error': {'message': 'Rate limit reached for model `meta-llama/llama-4-maverick-17b-128e-instruct` in organization `org_01kahypfxmfw0sea725ejt1d2j` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 497564, Requested 3637. Please try again in 3m27.5328s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}. Retrying in 60 seconds...\n",
      "Error occurred: Error code: 429 - {'error': {'message': 'Rate limit reached for model `meta-llama/llama-4-maverick-17b-128e-instruct` in organization `org_01kahypfxmfw0sea725ejt1d2j` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 497216, Requested 3637. Please try again in 2m27.3984s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}. Retrying in 60 seconds...\n",
      "Error occurred: Error code: 429 - {'error': {'message': 'Rate limit reached for model `meta-llama/llama-4-maverick-17b-128e-instruct` in organization `org_01kahypfxmfw0sea725ejt1d2j` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 496868, Requested 3637. Please try again in 1m27.264s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}. Retrying in 60 seconds...\n",
      "60\n",
      "Error occurred: Error code: 429 - {'error': {'message': 'Rate limit reached for model `meta-llama/llama-4-maverick-17b-128e-instruct` in organization `org_01kahypfxmfw0sea725ejt1d2j` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499653, Requested 2473. Please try again in 6m7.3728s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}. Retrying in 60 seconds...\n",
      "Error occurred: Error code: 429 - {'error': {'message': 'Rate limit reached for model `meta-llama/llama-4-maverick-17b-128e-instruct` in organization `org_01kahypfxmfw0sea725ejt1d2j` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 499305, Requested 2473. Please try again in 5m7.2384s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}. Retrying in 60 seconds...\n",
      "Error occurred: Error code: 429 - {'error': {'message': 'Rate limit reached for model `meta-llama/llama-4-maverick-17b-128e-instruct` in organization `org_01kahypfxmfw0sea725ejt1d2j` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 498957, Requested 2473. Please try again in 4m7.104s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}. Retrying in 60 seconds...\n",
      "Error occurred: Error code: 429 - {'error': {'message': 'Rate limit reached for model `meta-llama/llama-4-maverick-17b-128e-instruct` in organization `org_01kahypfxmfw0sea725ejt1d2j` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 498609, Requested 2473. Please try again in 3m6.9696s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}. Retrying in 60 seconds...\n",
      "Error occurred: Error code: 429 - {'error': {'message': 'Rate limit reached for model `meta-llama/llama-4-maverick-17b-128e-instruct` in organization `org_01kahypfxmfw0sea725ejt1d2j` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 498261, Requested 2473. Please try again in 2m6.835199999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}. Retrying in 60 seconds...\n",
      "Error occurred: Error code: 429 - {'error': {'message': 'Rate limit reached for model `meta-llama/llama-4-maverick-17b-128e-instruct` in organization `org_01kahypfxmfw0sea725ejt1d2j` service tier `on_demand` on tokens per day (TPD): Limit 500000, Used 497913, Requested 2473. Please try again in 1m6.7008s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}. Retrying in 60 seconds...\n",
      "40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.738)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = \"meta-llama/llama-4-maverick-17b-128e-instruct\"\n",
    "chunk_size = 60\n",
    "all_predictions, all_responses = predict_sentiments_groq(sample_text=sample_text, \n",
    "                                          chunk_size=chunk_size, \n",
    "                                          model=model, \n",
    "                                          few_shot=True, \n",
    "                                          cot=True, \n",
    "                                          binary=False)\n",
    "test['pred_cot_5s'] = pd.DataFrame(all_predictions)['sentiment_rating'].astype(int)\n",
    "(test['pred_cot_5s'] == test['rating']).sum()/len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff37face",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_llama.to_csv(\"results/test_10k_5_with_llm_llama_4_128e_preds.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e2bdd8",
   "metadata": {},
   "source": [
    "# GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "705696bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "## GPT-o5\n",
    "from groq import Groq\n",
    "\n",
    "client_groq = Groq()\n",
    "model = \"openai/gpt-oss-120b\"\n",
    "chunk_size = 50\n",
    "\n",
    "all_predictions = predict_sentiments_groq(sample_text=sample_text, \n",
    "                                         chunk_size=chunk_size, \n",
    "                                         model=model,\n",
    "                                         few_shot=False,\n",
    "                                         cot=False,\n",
    "                                         binary=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1ad50e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.712)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['pred_gpt_0s'] = pd.DataFrame(all_predictions)['sentiment_rating'].astype(int)\n",
    "(test['pred_gpt_0s'] == test['rating']).sum()/len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84f2d588",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv(\"results/test_10k_5_with_llm_gpt_oss_120b_preds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae868b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.704)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## GPT-o5\n",
    "from groq import Groq\n",
    "\n",
    "client_groq = Groq()\n",
    "model = \"openai/gpt-oss-120b\"\n",
    "chunk_size = 50\n",
    "\n",
    "all_predictions, all_responses = predict_sentiments_groq(sample_text=sample_text, \n",
    "                                         chunk_size=chunk_size, \n",
    "                                         model=model,\n",
    "                                         few_shot=True,\n",
    "                                         cot=False,\n",
    "                                         binary=False) \n",
    "test['pred_gpt_5s'] = pd.DataFrame(all_predictions)['sentiment_rating'].astype(int)\n",
    "(test['pred_gpt_5s'] == test['rating']).sum()/len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8140954c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>pred_gpt_0s</th>\n",
       "      <th>pred_gpt_5s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Used to freshen up linens</td>\n",
       "      <td>Used to freshen up linens</td>\n",
       "      <td>[    0 47640     7 21862  2457    62 24248  12...</td>\n",
       "      <td>[1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>need more proof:(to order!!!!</td>\n",
       "      <td>need more proof:(to order!!!!</td>\n",
       "      <td>[    0 30484    55  6461 48329   560   645 323...</td>\n",
       "      <td>[1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>This is a good flat iron, it has different tem...</td>\n",
       "      <td>This is a good flat iron, it has different tem...</td>\n",
       "      <td>[    0   713    16    10   205  3269  6440    ...</td>\n",
       "      <td>[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>This is the best gel I’ve tried.  Super hold w...</td>\n",
       "      <td>This is the best gel I’ve tried. Super hold wi...</td>\n",
       "      <td>[    0   713    16     5   275 17916    38    ...</td>\n",
       "      <td>[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>It comes with 1 set of the 4 smaller sizes and...</td>\n",
       "      <td>It comes with 1 set of the 4 smaller sizes and...</td>\n",
       "      <td>[    0   243   606    19   112   278     9    ...</td>\n",
       "      <td>[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Very effective. Can see good change :)</td>\n",
       "      <td>Very effective. Can see good change :)</td>\n",
       "      <td>[    0 25101  2375     4  2615   192   205   4...</td>\n",
       "      <td>[1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>4.0</td>\n",
       "      <td>This product works!  The treatment works on sh...</td>\n",
       "      <td>This product works! The treatment works on she...</td>\n",
       "      <td>[    0   713  1152  1364   328    20  1416  13...</td>\n",
       "      <td>[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Great price. Great product, and very fast ship...</td>\n",
       "      <td>Great price. Great product, and very fast ship...</td>\n",
       "      <td>[    0 19065   425     4  2860  1152     6    ...</td>\n",
       "      <td>[1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>3.0</td>\n",
       "      <td>I actually liked the hair. It did shed a littl...</td>\n",
       "      <td>I actually liked the hair. It did shed a littl...</td>\n",
       "      <td>[    0   100   888  6640     5  2549     4    ...</td>\n",
       "      <td>[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not at all what was expected. Does not apply a...</td>\n",
       "      <td>Not at all what was expected. Does not apply a...</td>\n",
       "      <td>[    0  7199    23    70    99    21   421    ...</td>\n",
       "      <td>[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  rating                                               text  \\\n",
       "0             0     4.0                          Used to freshen up linens   \n",
       "1             1     0.0                      need more proof:(to order!!!!   \n",
       "2             2     4.0  This is a good flat iron, it has different tem...   \n",
       "3             3     4.0  This is the best gel I’ve tried.  Super hold w...   \n",
       "4             4     4.0  It comes with 1 set of the 4 smaller sizes and...   \n",
       "..          ...     ...                                                ...   \n",
       "995         995     4.0             Very effective. Can see good change :)   \n",
       "996         996     4.0  This product works!  The treatment works on sh...   \n",
       "997         997     4.0  Great price. Great product, and very fast ship...   \n",
       "998         998     3.0  I actually liked the hair. It did shed a littl...   \n",
       "999         999     0.0  Not at all what was expected. Does not apply a...   \n",
       "\n",
       "                                          text_cleaned  \\\n",
       "0                            Used to freshen up linens   \n",
       "1                        need more proof:(to order!!!!   \n",
       "2    This is a good flat iron, it has different tem...   \n",
       "3    This is the best gel I’ve tried. Super hold wi...   \n",
       "4    It comes with 1 set of the 4 smaller sizes and...   \n",
       "..                                                 ...   \n",
       "995             Very effective. Can see good change :)   \n",
       "996  This product works! The treatment works on she...   \n",
       "997  Great price. Great product, and very fast ship...   \n",
       "998  I actually liked the hair. It did shed a littl...   \n",
       "999  Not at all what was expected. Does not apply a...   \n",
       "\n",
       "                                             input_ids  \\\n",
       "0    [    0 47640     7 21862  2457    62 24248  12...   \n",
       "1    [    0 30484    55  6461 48329   560   645 323...   \n",
       "2    [    0   713    16    10   205  3269  6440    ...   \n",
       "3    [    0   713    16     5   275 17916    38    ...   \n",
       "4    [    0   243   606    19   112   278     9    ...   \n",
       "..                                                 ...   \n",
       "995  [    0 25101  2375     4  2615   192   205   4...   \n",
       "996  [    0   713  1152  1364   328    20  1416  13...   \n",
       "997  [    0 19065   425     4  2860  1152     6    ...   \n",
       "998  [    0   100   888  6640     5  2549     4    ...   \n",
       "999  [    0  7199    23    70    99    21   421    ...   \n",
       "\n",
       "                                        attention_mask  pred_gpt_0s  \\\n",
       "0    [1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0...            3   \n",
       "1    [1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0...            1   \n",
       "2    [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...            4   \n",
       "3    [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...            4   \n",
       "4    [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...            3   \n",
       "..                                                 ...          ...   \n",
       "995  [1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0...            4   \n",
       "996  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...            4   \n",
       "997  [1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0...            4   \n",
       "998  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...            3   \n",
       "999  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...            0   \n",
       "\n",
       "     pred_gpt_5s  \n",
       "0              3  \n",
       "1              1  \n",
       "2              4  \n",
       "3              4  \n",
       "4              4  \n",
       "..           ...  \n",
       "995            4  \n",
       "996            4  \n",
       "997            4  \n",
       "998            3  \n",
       "999            0  \n",
       "\n",
       "[1000 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test.to_csv(\"results/test_10k_5_with_llm_gpt_oss_120b_preds.csv\")\n",
    "test_gpt = pd.read_csv(\"results/test_10k_5_with_llm_gpt_oss_120b_preds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a30cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_predictions, all_responses = all_predictions[0], all_predictions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45a4ae15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>sentiment_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index sentiment_rating\n",
       "0       0                3\n",
       "1       1                1\n",
       "2       2                4\n",
       "3       3                4\n",
       "4       4                3\n",
       "..    ...              ...\n",
       "995   995                4\n",
       "996   996                4\n",
       "997   997                4\n",
       "998   998                3\n",
       "999   999                0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a66c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.713\n"
     ]
    }
   ],
   "source": [
    "# ## GPT-o5\n",
    "# from groq import Groq\n",
    "\n",
    "client_groq = Groq()\n",
    "model = \"openai/gpt-oss-120b\"\n",
    "chunk_size = 50\n",
    "\n",
    "all_predictions, all_responses = predict_sentiments_groq(sample_text=sample_text, \n",
    "                                         chunk_size=chunk_size, \n",
    "                                         model=model,\n",
    "                                         few_shot=False,\n",
    "                                         cot=True,\n",
    "                                         binary=False) \n",
    "test_gpt['pred_gpt_cot'] = pd.DataFrame(all_predictions)['sentiment_rating'].astype(int)\n",
    "print((test_gpt['pred_gpt_cot'] == test_gpt['rating']).sum()/len(test_gpt))\n",
    "test_gpt.to_csv(\"results/test_10k_5_with_llm_gpt_oss_120b_preds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a8f57e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "## GPT-o5\n",
    "from groq import Groq\n",
    "\n",
    "client_groq = Groq()\n",
    "model = \"openai/gpt-oss-120b\"\n",
    "chunk_size = 50\n",
    "\n",
    "all_predictions, all_responses = predict_sentiments_groq(sample_text=sample_text, \n",
    "                                         chunk_size=chunk_size, \n",
    "                                         model=model,\n",
    "                                         few_shot=True,\n",
    "                                         cot=True,\n",
    "                                         binary=False) \n",
    "\n",
    "test_gpt['pred_gpt_cot_5s'] = pd.DataFrame(all_predictions)['sentiment_rating'].astype(int)\n",
    "(test_gpt['pred_gpt_cot_5s'] == test_gpt['rating']).sum()/len(test_gpt)\n",
    "test_gpt.to_csv(\"results/test_10k_5_with_llm_gpt_oss_120b_preds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fa31449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.717)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test_gpt['pred_gpt_cot_5s'] == test_gpt['rating']).sum()/len(test_gpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe3b77f",
   "metadata": {},
   "source": [
    "## qwen/qwen3-32b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2392950",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_qwen = pd.read_parquet(\"data/test_10k_5.parquet\")\n",
    "sample_text_qwen = test_qwen.text.to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5e0ee80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.626)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = \"qwen/qwen3-32b\"\n",
    "chunk_size = 60\n",
    "\n",
    "# all_predictions, all_responses = predict_sentiments_groq(sample_text=sample_text_qwen, \n",
    "#                                          chunk_size=chunk_size, \n",
    "#                                          model=model,\n",
    "#                                          few_shot=False,\n",
    "#                                          cot=False,\n",
    "#                                          binary=False,\n",
    "#                                          response_format=False) \n",
    "all_pred = pd.DataFrame()\n",
    "for i in all_responses:\n",
    "    content = i.split('</think>')[-1].replace('```json', '').replace('```', '').strip()\n",
    "    json_content = json.loads(content)\n",
    "    try:\n",
    "        df = pd.DataFrame(json_content['reviews'])\n",
    "    except Exception as e:\n",
    "        df = pd.DataFrame(json_content)\n",
    "        # break\n",
    "    all_pred = pd.concat([all_pred, df], ignore_index=True)\n",
    "\n",
    "test_qwen['pred_qwen3_0s'] = pd.DataFrame(all_pred)['sentiment'].astype(int)\n",
    "(test_qwen['pred_qwen3_0s'] == test_qwen['rating']).sum()/len(test_qwen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00fe6131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57ff059c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_qwen.to_csv(\"results/test_10k_5_with_qwen_preds.csv\")\n",
    "test_qwen = pd.read_csv(\"results/test_10k_5_with_qwen_preds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80d86589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>sentiment_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index sentiment_rating\n",
       "0       0                2\n",
       "1       1                1\n",
       "2       2                4\n",
       "3       3                4\n",
       "4       4                3\n",
       "..    ...              ...\n",
       "995   995                3\n",
       "996   996                3\n",
       "997   997                4\n",
       "998   998                2\n",
       "999   999                0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ffa3c686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.663)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = \"qwen/qwen3-32b\"\n",
    "chunk_size = 60\n",
    "\n",
    "# all_predictions, all_responses = predict_sentiments_groq(sample_text=sample_text, \n",
    "#                                          chunk_size=chunk_size, \n",
    "#                                          model=model,\n",
    "#                                          few_shot=True,\n",
    "#                                          cot=False,\n",
    "#                                          binary=False,\n",
    "#                                          response_format=False) \n",
    "all_pred = pd.DataFrame()\n",
    "for i in all_responses:\n",
    "    content = i.split('</think>')[-1].replace('```json', '').replace('```', '').strip()\n",
    "    json_content = json.loads(content)\n",
    "    try:\n",
    "        df = pd.DataFrame(json_content['reviews'])\n",
    "    except Exception as e:\n",
    "        df = pd.DataFrame(json_content)\n",
    "        # break\n",
    "    all_pred = pd.concat([all_pred, df], ignore_index=True)\n",
    "\n",
    "df_temp = pd.DataFrame(all_predictions)\n",
    "test_qwen['pred_qwen3_5s'] = df_temp['sentiment_rating'].astype(int)\n",
    "(test_qwen['pred_qwen3_5s'] == test_qwen['rating']).sum()/len(test_qwen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a8f3164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>pred_qwen3_0s</th>\n",
       "      <th>pred_qwen3_5s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Used to freshen up linens</td>\n",
       "      <td>Used to freshen up linens</td>\n",
       "      <td>[    0 47640     7 21862  2457    62 24248  12...</td>\n",
       "      <td>[1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>need more proof:(to order!!!!</td>\n",
       "      <td>need more proof:(to order!!!!</td>\n",
       "      <td>[    0 30484    55  6461 48329   560   645 323...</td>\n",
       "      <td>[1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>This is a good flat iron, it has different tem...</td>\n",
       "      <td>This is a good flat iron, it has different tem...</td>\n",
       "      <td>[    0   713    16    10   205  3269  6440    ...</td>\n",
       "      <td>[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>This is the best gel I’ve tried.  Super hold w...</td>\n",
       "      <td>This is the best gel I’ve tried. Super hold wi...</td>\n",
       "      <td>[    0   713    16     5   275 17916    38    ...</td>\n",
       "      <td>[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>It comes with 1 set of the 4 smaller sizes and...</td>\n",
       "      <td>It comes with 1 set of the 4 smaller sizes and...</td>\n",
       "      <td>[    0   243   606    19   112   278     9    ...</td>\n",
       "      <td>[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Very effective. Can see good change :)</td>\n",
       "      <td>Very effective. Can see good change :)</td>\n",
       "      <td>[    0 25101  2375     4  2615   192   205   4...</td>\n",
       "      <td>[1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>4.0</td>\n",
       "      <td>This product works!  The treatment works on sh...</td>\n",
       "      <td>This product works! The treatment works on she...</td>\n",
       "      <td>[    0   713  1152  1364   328    20  1416  13...</td>\n",
       "      <td>[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Great price. Great product, and very fast ship...</td>\n",
       "      <td>Great price. Great product, and very fast ship...</td>\n",
       "      <td>[    0 19065   425     4  2860  1152     6    ...</td>\n",
       "      <td>[1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>3.0</td>\n",
       "      <td>I actually liked the hair. It did shed a littl...</td>\n",
       "      <td>I actually liked the hair. It did shed a littl...</td>\n",
       "      <td>[    0   100   888  6640     5  2549     4    ...</td>\n",
       "      <td>[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not at all what was expected. Does not apply a...</td>\n",
       "      <td>Not at all what was expected. Does not apply a...</td>\n",
       "      <td>[    0  7199    23    70    99    21   421    ...</td>\n",
       "      <td>[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  rating                                               text  \\\n",
       "0             0     4.0                          Used to freshen up linens   \n",
       "1             1     0.0                      need more proof:(to order!!!!   \n",
       "2             2     4.0  This is a good flat iron, it has different tem...   \n",
       "3             3     4.0  This is the best gel I’ve tried.  Super hold w...   \n",
       "4             4     4.0  It comes with 1 set of the 4 smaller sizes and...   \n",
       "..          ...     ...                                                ...   \n",
       "995         995     4.0             Very effective. Can see good change :)   \n",
       "996         996     4.0  This product works!  The treatment works on sh...   \n",
       "997         997     4.0  Great price. Great product, and very fast ship...   \n",
       "998         998     3.0  I actually liked the hair. It did shed a littl...   \n",
       "999         999     0.0  Not at all what was expected. Does not apply a...   \n",
       "\n",
       "                                          text_cleaned  \\\n",
       "0                            Used to freshen up linens   \n",
       "1                        need more proof:(to order!!!!   \n",
       "2    This is a good flat iron, it has different tem...   \n",
       "3    This is the best gel I’ve tried. Super hold wi...   \n",
       "4    It comes with 1 set of the 4 smaller sizes and...   \n",
       "..                                                 ...   \n",
       "995             Very effective. Can see good change :)   \n",
       "996  This product works! The treatment works on she...   \n",
       "997  Great price. Great product, and very fast ship...   \n",
       "998  I actually liked the hair. It did shed a littl...   \n",
       "999  Not at all what was expected. Does not apply a...   \n",
       "\n",
       "                                             input_ids  \\\n",
       "0    [    0 47640     7 21862  2457    62 24248  12...   \n",
       "1    [    0 30484    55  6461 48329   560   645 323...   \n",
       "2    [    0   713    16    10   205  3269  6440    ...   \n",
       "3    [    0   713    16     5   275 17916    38    ...   \n",
       "4    [    0   243   606    19   112   278     9    ...   \n",
       "..                                                 ...   \n",
       "995  [    0 25101  2375     4  2615   192   205   4...   \n",
       "996  [    0   713  1152  1364   328    20  1416  13...   \n",
       "997  [    0 19065   425     4  2860  1152     6    ...   \n",
       "998  [    0   100   888  6640     5  2549     4    ...   \n",
       "999  [    0  7199    23    70    99    21   421    ...   \n",
       "\n",
       "                                        attention_mask  pred_qwen3_0s  \\\n",
       "0    [1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0...              2   \n",
       "1    [1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0...              1   \n",
       "2    [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...              3   \n",
       "3    [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...              4   \n",
       "4    [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...              2   \n",
       "..                                                 ...            ...   \n",
       "995  [1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0...              3   \n",
       "996  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...              4   \n",
       "997  [1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0...              4   \n",
       "998  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...              2   \n",
       "999  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...              0   \n",
       "\n",
       "     pred_qwen3_5s  \n",
       "0                2  \n",
       "1                1  \n",
       "2                4  \n",
       "3                4  \n",
       "4                3  \n",
       "..             ...  \n",
       "995              3  \n",
       "996              3  \n",
       "997              4  \n",
       "998              2  \n",
       "999              0  \n",
       "\n",
       "[1000 rows x 8 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_qwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1fe451d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_qwen.to_csv(\"results/test_10k_5_with_qwen_preds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "821f02ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred: Connection error.. Retrying in 60 seconds...\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.654)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = \"qwen/qwen3-32b\"\n",
    "chunk_size = 60\n",
    "\n",
    "all_predictions, all_responses = predict_sentiments_groq(sample_text=sample_text, \n",
    "                                         chunk_size=chunk_size, \n",
    "                                         model=model,\n",
    "                                         few_shot=False,\n",
    "                                         cot=True,\n",
    "                                         binary=False,\n",
    "                                         response_format=False) \n",
    "all_pred = pd.DataFrame()\n",
    "for i in all_responses:\n",
    "    content = i.split('</think>')[-1].replace('```json', '').replace('```', '').strip()\n",
    "    json_content = json.loads(content)\n",
    "    try:\n",
    "        df = pd.DataFrame(json_content['reviews'])\n",
    "    except Exception as e:\n",
    "        df = pd.DataFrame(json_content)\n",
    "        # break\n",
    "    all_pred = pd.concat([all_pred, df], ignore_index=True)\n",
    "\n",
    "test_qwen['pred_qwen3_cot'] = pd.DataFrame(all_predictions)['sentiment'].astype(int)\n",
    "(test_qwen['pred_qwen3_cot'] == test_qwen['rating']).sum()/len(test_qwen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f700dcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>pred_qwen3_0s</th>\n",
       "      <th>pred_qwen3_5s</th>\n",
       "      <th>pred_qwen3_cot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Used to freshen up linens</td>\n",
       "      <td>Used to freshen up linens</td>\n",
       "      <td>[    0 47640     7 21862  2457    62 24248  12...</td>\n",
       "      <td>[1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>need more proof:(to order!!!!</td>\n",
       "      <td>need more proof:(to order!!!!</td>\n",
       "      <td>[    0 30484    55  6461 48329   560   645 323...</td>\n",
       "      <td>[1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>This is a good flat iron, it has different tem...</td>\n",
       "      <td>This is a good flat iron, it has different tem...</td>\n",
       "      <td>[    0   713    16    10   205  3269  6440    ...</td>\n",
       "      <td>[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>This is the best gel I’ve tried.  Super hold w...</td>\n",
       "      <td>This is the best gel I’ve tried. Super hold wi...</td>\n",
       "      <td>[    0   713    16     5   275 17916    38    ...</td>\n",
       "      <td>[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>It comes with 1 set of the 4 smaller sizes and...</td>\n",
       "      <td>It comes with 1 set of the 4 smaller sizes and...</td>\n",
       "      <td>[    0   243   606    19   112   278     9    ...</td>\n",
       "      <td>[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Very effective. Can see good change :)</td>\n",
       "      <td>Very effective. Can see good change :)</td>\n",
       "      <td>[    0 25101  2375     4  2615   192   205   4...</td>\n",
       "      <td>[1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>4.0</td>\n",
       "      <td>This product works!  The treatment works on sh...</td>\n",
       "      <td>This product works! The treatment works on she...</td>\n",
       "      <td>[    0   713  1152  1364   328    20  1416  13...</td>\n",
       "      <td>[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Great price. Great product, and very fast ship...</td>\n",
       "      <td>Great price. Great product, and very fast ship...</td>\n",
       "      <td>[    0 19065   425     4  2860  1152     6    ...</td>\n",
       "      <td>[1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>3.0</td>\n",
       "      <td>I actually liked the hair. It did shed a littl...</td>\n",
       "      <td>I actually liked the hair. It did shed a littl...</td>\n",
       "      <td>[    0   100   888  6640     5  2549     4    ...</td>\n",
       "      <td>[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not at all what was expected. Does not apply a...</td>\n",
       "      <td>Not at all what was expected. Does not apply a...</td>\n",
       "      <td>[    0  7199    23    70    99    21   421    ...</td>\n",
       "      <td>[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  rating                                               text  \\\n",
       "0             0     4.0                          Used to freshen up linens   \n",
       "1             1     0.0                      need more proof:(to order!!!!   \n",
       "2             2     4.0  This is a good flat iron, it has different tem...   \n",
       "3             3     4.0  This is the best gel I’ve tried.  Super hold w...   \n",
       "4             4     4.0  It comes with 1 set of the 4 smaller sizes and...   \n",
       "..          ...     ...                                                ...   \n",
       "995         995     4.0             Very effective. Can see good change :)   \n",
       "996         996     4.0  This product works!  The treatment works on sh...   \n",
       "997         997     4.0  Great price. Great product, and very fast ship...   \n",
       "998         998     3.0  I actually liked the hair. It did shed a littl...   \n",
       "999         999     0.0  Not at all what was expected. Does not apply a...   \n",
       "\n",
       "                                          text_cleaned  \\\n",
       "0                            Used to freshen up linens   \n",
       "1                        need more proof:(to order!!!!   \n",
       "2    This is a good flat iron, it has different tem...   \n",
       "3    This is the best gel I’ve tried. Super hold wi...   \n",
       "4    It comes with 1 set of the 4 smaller sizes and...   \n",
       "..                                                 ...   \n",
       "995             Very effective. Can see good change :)   \n",
       "996  This product works! The treatment works on she...   \n",
       "997  Great price. Great product, and very fast ship...   \n",
       "998  I actually liked the hair. It did shed a littl...   \n",
       "999  Not at all what was expected. Does not apply a...   \n",
       "\n",
       "                                             input_ids  \\\n",
       "0    [    0 47640     7 21862  2457    62 24248  12...   \n",
       "1    [    0 30484    55  6461 48329   560   645 323...   \n",
       "2    [    0   713    16    10   205  3269  6440    ...   \n",
       "3    [    0   713    16     5   275 17916    38    ...   \n",
       "4    [    0   243   606    19   112   278     9    ...   \n",
       "..                                                 ...   \n",
       "995  [    0 25101  2375     4  2615   192   205   4...   \n",
       "996  [    0   713  1152  1364   328    20  1416  13...   \n",
       "997  [    0 19065   425     4  2860  1152     6    ...   \n",
       "998  [    0   100   888  6640     5  2549     4    ...   \n",
       "999  [    0  7199    23    70    99    21   421    ...   \n",
       "\n",
       "                                        attention_mask  pred_qwen3_0s  \\\n",
       "0    [1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0...              2   \n",
       "1    [1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0...              1   \n",
       "2    [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...              3   \n",
       "3    [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...              4   \n",
       "4    [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...              2   \n",
       "..                                                 ...            ...   \n",
       "995  [1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0...              3   \n",
       "996  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...              4   \n",
       "997  [1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0...              4   \n",
       "998  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...              2   \n",
       "999  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1...              0   \n",
       "\n",
       "     pred_qwen3_5s  pred_qwen3_cot  \n",
       "0                2               3  \n",
       "1                1               1  \n",
       "2                4               4  \n",
       "3                4               4  \n",
       "4                3               3  \n",
       "..             ...             ...  \n",
       "995              3               4  \n",
       "996              3               3  \n",
       "997              4               4  \n",
       "998              2               3  \n",
       "999              0               0  \n",
       "\n",
       "[1000 rows x 9 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_qwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0ab22dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_qwen.to_csv(\"results/test_10k_5_with_qwen_preds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e88a3b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.684)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = \"qwen/qwen3-32b\"\n",
    "chunk_size = 60\n",
    "\n",
    "# all_predictions, all_responses = predict_sentiments_groq(sample_text=sample_text, \n",
    "#                                          chunk_size=chunk_size, \n",
    "#                                          model=model,\n",
    "#                                          few_shot=True,\n",
    "#                                          cot=True,\n",
    "#                                          binary=False,\n",
    "#                                          response_format=False) \n",
    "all_pred = pd.DataFrame()\n",
    "for i in all_responses:\n",
    "    content = i.split('</think>')[-1].replace('```json', '').replace('```', '').strip()\n",
    "    json_content = json.loads(content)\n",
    "    try:\n",
    "        df = pd.DataFrame(json_content['reviews'])\n",
    "    except Exception as e:\n",
    "        df = pd.DataFrame(json_content)\n",
    "        # break\n",
    "    all_pred = pd.concat([all_pred, df], ignore_index=True)\n",
    "all_pred['sentiment_rating'] = np.where(all_pred['sentiment_rating'].notna(),\n",
    "                                       all_pred['sentiment_rating'],\n",
    "                                        all_pred['sentiment_rate'])\n",
    "\n",
    "test_qwen['pred_qwen3_cot_5s'] = all_pred['sentiment_rating'].astype(int)\n",
    "(test_qwen['pred_qwen3_cot_5s'] == test_qwen['rating']).sum()/len(test_qwen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bfc505e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_qwen.to_csv(\"results/test_10k_5_with_qwen_preds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "265cf7fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>sentiment_rating</th>\n",
       "      <th>sentiment_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index sentiment_rating sentiment_rate\n",
       "0       0                2            NaN\n",
       "1       1                1            NaN\n",
       "2       2                4            NaN\n",
       "3       3                4            NaN\n",
       "4       4                3            NaN\n",
       "..    ...              ...            ...\n",
       "995   995                4            NaN\n",
       "996   996                4            NaN\n",
       "997   997                4            NaN\n",
       "998   998                3            NaN\n",
       "999   999                0            NaN\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f879fff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data512_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
